EventId,EventTemplate
E1,Created MRAppMaster for application <*>
E2,Executing with <*>
E3,"Kind: <*>, Service: <*>, Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"
E4,Using <*> newApiCommitter.
E5,OutputCommitter set in config <*>
E6,OutputCommitter is <*>
E7,Registering class <*> for class <*>
E8,Default file system [hdfs://<*>]
E9,Emitting job history data to the timeline server is not enabled
E10,loaded properties from <*>
E11,Scheduled snapshot period at <*> second(s).
E12,<*> metrics system started
E13,Adding job token for <*> to jobTokenSecretManager
E14,Not uberizing <*> because: not enabled; too many maps; too much input;
E15,Input size for job <*> = <*>. Number of splits = <*>
E16,Number of reduces for job <*> = <*>
E17,<*> Transitioned from <*> to <*>
E18,"MRAppMaster launching normal, non-uberized, multi-container job <*>."
E19,Using callQueue class <*>
E20,Starting Socket Reader <*> for port <*>
E21,Adding protocol <*> to the server
E22,Instantiated MRClientService at <*>
E23,IPC Server Responder: <*>
E24,IPC Server listener on <*>: starting
E25,Logging to <*> via <*>
E26,Http request log for <*> is not defined
E27,Added global filter <*> (class=<*>)
E28,Added filter <*> (class=<*>) to context <*>
E29,adding path spec: <*>
E30,Jetty bound to port <*>
E31,jetty-<*>
E32,Extract jar:<*> to <*>
E33,Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>
E34,Web app <*> started at <*>
E35,Registered webapp <*> modules
E36,JOB_CREATE <*>
E37,nodeBlacklistingEnabled:true
E38,maxTaskFailuresPerNode is <*>
E39,blacklistDisablePercent is <*>
E40,Connecting to ResourceManager at <*>
E41,"maxContainerCapability: <memory:<*>, vCores:<*>"
E42,queue: <*>
E43,Upper limit on the thread pool size is <*>
E44,yarn.client.max-cached-nodemanagers-proxies : <*>
E45,Processing the event EventType: <*>
E46,Resolved <*> to <*>
E47,"mapResourceRequest:<memory:<*>, vCores:<*>"
E48,"Event Writer setup for JobId: <*>, File: <*>"
E49,"reduceResourceRequest:<memory:<*>, vCores:<*>"
E50,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
E51,"getResources() for <*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>"
E52,"Recalculating schedule, headroom=<memory:<*>, vCores:<*>"
E53,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
E54,Got allocated containers <*>
E55,Assigned container <*> to <*>
E56,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
E57,The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/<*>/job.jar
E58,The job-conf file on the remote FS is <*>
E59,Adding <*> tokens and <*> secret keys for NM use for launching container
E60,Size of containertokens_dob is <*>
E61,Putting shuffle token in <*>
E62,Launching <*>
E63,Opening proxy : <*>
E64,Shuffle port returned by ContainerManager for <*> : <*>
E65,TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]
E66,ATTEMPT_START <*>
E67,Auth successful for <*> (auth:<*>)
E68,JVM with ID : <*> asked for a task
E69,JVM with ID: <*> given task: <*>
E70,Progress of TaskAttempt <*> is : <*>
E71,"Cannot assign container Container: [ContainerId: <*>, NodeId: <*>, NodeHttpAddress: <*>, Resource: <*>, Priority: <*>, Token: Token { kind: <*>, service: <*> }, ] for a map as either container memory less than required <*> or no pending map tasks - maps.isEmpty=<*>"
E72,Received completed container <*>
E73,Container complete event for unknown container id <*>
E74,Done acknowledgement from <*>
E75,KILLING <*>
E76,Task succeeded with attempt <*>
E77,Num completed Tasks: <*>
E78,Reduce slow start threshold reached. Scheduling <*>.
E79,All maps assigned. Ramping up all remaining reduces:<*>
E80,DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
E81,We launched <*> speculations. Sleeping <*> milliseconds.
E82,Scheduling a redundant attempt for task <*>
E83,Diagnostics report from <*>: Container killed by the ApplicationMaster.
E84,Address change detected. Old: <*> New: <*>
E85,Failed to renew lease for <*> for <*> seconds. Will retry shortly ...
E86,"Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*>, targets: [<*>, <*>]"
E87,DFSOutputStream ResponseProcessor exception for block <*>
E88,"Error Recovery for block <*> in pipeline <*>, <*>: bad datanode <*>"
E89,DataStreamer <*>
E90,ERROR IN CONTACTING RM.
E91,"Retrying connect to server: <*>. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)"
E92,Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-<*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
E93,Diagnostics report from <*>: Error: java.net.NoRouteToHostException: No Route to Host from MININT-<*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
E94,Task cleanup failed for attempt <*>
E95,Error writing History Event: <*>
E96,"Thread Thread[eventHandlingThread,<*>,main] threw an Exception."
E97,<*> failures on node MININT-<*>.fareast.corp.microsoft.com
E98,Added <*> to list of failed maps
