{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing HealthApp dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:30<00:00, 22.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing OpenStack dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:35<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Zookeeper dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:51<00:00, 38.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mac dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:50<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hadoop dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:06<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Android dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:26<00:00, 23.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Windows dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:18<00:00, 25.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Apache dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:04<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Thunderbird dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:31<00:00, 63.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Spark dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:03<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Linux dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 57/2000 [00:05<03:04, 10.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m prompt_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(prompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompt_list]\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 48\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmap/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     52\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mmap\u001b[39m, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32md:\\Develop\\anaconda\\envs\\langchain38\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Develop\\anaconda\\envs\\langchain38\\lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32md:\\Develop\\anaconda\\envs\\langchain38\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32md:\\Develop\\anaconda\\envs\\langchain38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import httpx\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "CLIENT = OpenAI(\n",
    "    api_key='sk-proj-5EkdZfTfjJ1GJim17pgQT3BlbkFJHCMqWAOX7dTSGOcFOjrn',   # api_key\n",
    "    http_client=httpx.Client(\n",
    "            proxies=\"http://127.0.0.1:7890\"  # proxies\n",
    "    ),\n",
    ")\n",
    "\n",
    "map = {}\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(20), wait=wait_random_exponential(min=1, max=60))\n",
    "def get_response(prompt, dataset):\n",
    "\n",
    "    if prompt not in map:\n",
    "        response = CLIENT.chat.completions.create(\n",
    "            model='gpt-3.5-turbo-0125',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        output = response.choices[0].message.content.strip('\\n')\n",
    "        map[prompt] = output\n",
    "    else:\n",
    "        output = map[prompt]\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datasets = ['BGL', 'HDFS', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper',\n",
    "                'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark', 'Linux']\n",
    "    datasets = ['HealthApp', 'OpenStack', 'Zookeeper','Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark', 'Linux']\n",
    "    for dataset in datasets:\n",
    "        print(f'Processing {dataset} dataset')\n",
    "\n",
    "        prompt_list_path = f'cost_divlog_for_{dataset}.json'\n",
    "        with open(prompt_list_path, 'r') as f:\n",
    "            prompt_list = json.load(f)\n",
    "        prompt_list = [str(prompt) for prompt in prompt_list]\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "            outputs = list(\n",
    "                tqdm(executor.map(get_response, prompt_list, [dataset for _ in prompt_list]), total=len(prompt_list)))\n",
    "\n",
    "        with open(f'map/{dataset}.json', 'w') as f:\n",
    "            json.dump(map, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 11508.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 13909.63it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 19197.61it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 7779.89it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8549.04it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 26569.10it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 14730.94it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 8004.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 10063.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n",
      "alert2\n",
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1772/2000 [00:00<00:00, 8822.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n",
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 8939.59it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 9574.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 14439.67it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 11892.53it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 10715.30it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 11675.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extractResultTemplate(text):\n",
    "    # this pattern is for ChatGPT\n",
    "    # pattern = re.compile('<START> <Event\\d> (.+) <END>')\n",
    "    pattern = re.compile('<START> (.+) <END>')\n",
    "    # findall return a list\n",
    "    result = pattern.findall(text)\n",
    "    if (len(result)):\n",
    "        return result[0]\n",
    "    else: return \"\"\n",
    "\n",
    "def correct_single_template(template, user_strings=None):\n",
    "    \"\"\"Apply all rules to process a template.\n",
    "\n",
    "    DS (Double Space)\n",
    "    BL (Boolean)\n",
    "    US (User String)\n",
    "    DG (Digit)\n",
    "    PS (Path-like String)\n",
    "    WV (Word concatenated with Variable)\n",
    "    DV (Dot-separated Variables)\n",
    "    CV (Consecutive Variables)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    boolean = {'true', 'false'}\n",
    "    default_strings = {'null', 'root', 'admin'}\n",
    "    path_delimiters = {  # reduced set of delimiters for tokenizing for checking the path-like strings\n",
    "        r'\\s', r'\\,', r'\\!', r'\\;', r'\\:',\n",
    "        r'\\=', r'\\|', r'\\\"', r'\\'',\n",
    "        r'\\[', r'\\]', r'\\(', r'\\)', r'\\{', r'\\}'\n",
    "    }\n",
    "    token_delimiters = path_delimiters.union({  # all delimiters for tokenizing the remaining rules\n",
    "        r'\\.', r'\\-', r'\\+', r'\\@', r'\\#', r'\\$', r'\\%', r'\\&',\n",
    "    })\n",
    "\n",
    "    if user_strings:\n",
    "        default_strings = default_strings.union(user_strings)\n",
    "\n",
    "    # apply DS\n",
    "    # Note: this is not necessary while postprorcessing\n",
    "    template = template.strip()\n",
    "    template = re.sub(r'\\s+', ' ', template)\n",
    "\n",
    "    # apply PS\n",
    "    p_tokens = re.split('(' + '|'.join(path_delimiters) + ')', template)\n",
    "    new_p_tokens = []\n",
    "    for p_token in p_tokens:\n",
    "        if re.match(r'^(\\/[^\\/]+)+$', p_token):\n",
    "            p_token = '<*>'\n",
    "        new_p_tokens.append(p_token)\n",
    "    template = ''.join(new_p_tokens)\n",
    "\n",
    "    # tokenize for the remaining rules\n",
    "    tokens = re.split('(' + '|'.join(token_delimiters) + ')', template)  # tokenizing while keeping delimiters\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        # apply BL, US\n",
    "        for to_replace in boolean.union(default_strings):\n",
    "            if token.lower() == to_replace.lower():\n",
    "                token = '<*>'\n",
    "\n",
    "        # apply DG\n",
    "        # Note: hexadecimal num also appears a lot in the logs\n",
    "        if re.match(r'^\\d+$', token) or re.match(r'\\b0[xX][0-9a-fA-F]+\\b', token):\n",
    "            token = '<*>'\n",
    "\n",
    "        # apply WV\n",
    "        if re.match(r'^[^\\s\\/]*<\\*>[^\\s\\/]*$', token) or all(x in token for x in {'<*>', '.', '/'}) or all(x in token for x in {'<*>', '/', ':'}):\n",
    "            # if token != '<*>/<*>':  # need to check this because `/` is not a deliminator\n",
    "            token = '<*>'\n",
    "\n",
    "        # collect the result\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    # make the template using new_tokens\n",
    "    template = ''.join(new_tokens)\n",
    "\n",
    "    # Substitute consecutive variables only if separated with any delimiter including \".\" (DV)\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*>\\.<\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "\n",
    "    # Substitute consecutive variables only if not separated with any delimiter including space (CV)\n",
    "    # NOTE: this should be done at the end\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*><\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "    # incorrect in HealthApp\n",
    "    # while \"#<*>#\" in template:\n",
    "    #     template = template.replace(\"#<*>#\", \"<*>\")\n",
    "\n",
    "    while \"<*>:<*>\" in template:\n",
    "        template = template.replace(\"<*>:<*>\", \"<*>\")\n",
    "\n",
    "    while \"<*>/<*>\" in template:\n",
    "        template = template.replace(\"<*>/<*>\", \"<*>\")\n",
    "\n",
    "    return template\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper',\n",
    "            'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark', 'Linux']\n",
    "\n",
    "output_dir = 'result'\n",
    "# output file\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# datasets = ['BGL']\n",
    "for dataset in datasets:\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "\n",
    "    with open(f'cost_divlog_for_{dataset}.json', 'r') as f:\n",
    "        prompt_list = json.load(f)\n",
    "\n",
    "    with open(f'map/{dataset}.json', 'r') as f:\n",
    "        look_up_map = json.load(f)\n",
    "    results = []\n",
    "    look_up_map2 = {}\n",
    "    for prompt in tqdm(prompt_list):\n",
    "        log = prompt.split('\\n')[-2].replace('<prompt>:', '').strip()\n",
    "        template = prompt.split('\\n')[-4].replace('<extraction>: <START>', '').replace('<END>','').strip()\n",
    "        if prompt not in look_up_map:\n",
    "            print('alert1')\n",
    "            result = template\n",
    "            result = ''\n",
    "        else:\n",
    "            result = extractResultTemplate(look_up_map[prompt])\n",
    "            result = correct_single_template(result)\n",
    "            if result == '':\n",
    "                print('alert2')\n",
    "                result = template\n",
    "        look_up_map2[log] = result\n",
    "\n",
    "    for log in df['Content']:\n",
    "        if log.strip() in look_up_map2:\n",
    "            results.append(look_up_map2[log.strip()])\n",
    "        else:\n",
    "            results.append('')\n",
    "            print('alert3')\n",
    "\n",
    "    df['EventTemplate'] = results\n",
    "    df[['Content', 'EventTemplate']].to_csv(f'{output_dir}/{dataset}_2k.log_structured.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
