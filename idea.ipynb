{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Clustering HealthApp dataset...\n",
      "  (0, 100)\t1.0\n",
      "  (1, 97)\t1.0\n",
      "  (2, 16)\t0.6248332566193072\n",
      "  (2, 11)\t0.5520794333347835\n",
      "  (2, 98)\t0.5520794333347835\n",
      "  (3, 12)\t0.8517032026021748\n",
      "  (3, 105)\t0.5240244790820354\n",
      "  (4, 45)\t0.5668201002003888\n",
      "  (4, 121)\t0.5825439786011101\n",
      "  (4, 64)\t0.5825439786011101\n",
      "  (5, 72)\t1.0\n",
      "  (6, 125)\t1.0\n",
      "  (7, 100)\t1.0\n",
      "  (8, 156)\t0.7071067811865475\n",
      "  (8, 31)\t0.7071067811865475\n",
      "  (9, 155)\t0.7071067811865475\n",
      "  (9, 30)\t0.7071067811865475\n",
      "  (10, 0)\t0.7064072898835545\n",
      "  (10, 8)\t0.7078055812151892\n",
      "  (11, 97)\t1.0\n",
      "  (12, 100)\t1.0\n",
      "  (13, 100)\t1.0\n",
      "  (14, 97)\t1.0\n",
      "  (15, 72)\t1.0\n",
      "  (16, 125)\t1.0\n",
      "  :\t:\n",
      "  (1987, 105)\t0.6960412725776134\n",
      "  (1988, 13)\t0.7180017735831414\n",
      "  (1988, 105)\t0.6960412725776134\n",
      "  (1989, 13)\t0.7180017735831414\n",
      "  (1989, 105)\t0.6960412725776134\n",
      "  (1990, 13)\t0.7180017735831414\n",
      "  (1990, 105)\t0.6960412725776134\n",
      "  (1991, 13)\t0.7180017735831414\n",
      "  (1991, 105)\t0.6960412725776134\n",
      "  (1992, 13)\t0.7180017735831414\n",
      "  (1992, 105)\t0.6960412725776134\n",
      "  (1993, 13)\t0.7180017735831414\n",
      "  (1993, 105)\t0.6960412725776134\n",
      "  (1994, 13)\t0.7180017735831414\n",
      "  (1994, 105)\t0.6960412725776134\n",
      "  (1995, 13)\t0.7180017735831414\n",
      "  (1995, 105)\t0.6960412725776134\n",
      "  (1996, 13)\t0.7180017735831414\n",
      "  (1996, 105)\t0.6960412725776134\n",
      "  (1997, 13)\t0.7180017735831414\n",
      "  (1997, 105)\t0.6960412725776134\n",
      "  (1998, 13)\t0.7180017735831414\n",
      "  (1998, 105)\t0.6960412725776134\n",
      "  (1999, 13)\t0.7180017735831414\n",
      "  (1999, 105)\t0.6960412725776134\n",
      "onStandStepChanged 3579\n",
      "onStandStepChanged <*>\n",
      "260\n",
      "==================================================\n",
      "onExtend:1514038530000 14 0 4\n",
      "onExtend:<*> <*> <*> <*>\n",
      "273\n",
      "==================================================\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "17\n",
      "==================================================\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "17\n",
      "==================================================\n",
      "flush sensor data\n",
      "flush sensor data\n",
      "17\n",
      "==================================================\n",
      " getTodayTotalDetailSteps = 1514039760000##7189##549659##8661##16256##28479559\n",
      "getTodayTotalDetailSteps = <*>##<*>##<*>##<*>##<*>##<*>\n",
      "242\n",
      "==================================================\n",
      "setTodayTotalDetailSteps=1514038440000##7007##548365##8661##12361##27173954\n",
      "setTodayTotalDetailSteps=<*>##<*>##<*>##<*>##<*>##<*>\n",
      "241\n",
      "==================================================\n",
      "calculateCaloriesWithCache totalCalories=126775\n",
      "calculateCaloriesWithCache totalCalories=<*>\n",
      "241\n",
      "==================================================\n",
      "calculateAltitudeWithCache totalAltitude=240\n",
      "calculateAltitudeWithCache totalAltitude=<*>\n",
      "241\n",
      "==================================================\n",
      "REPORT : 7007 5002 150089 240\n",
      "REPORT : <*> <*> <*> <*>\n",
      "136\n",
      "==================================================\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "17\n",
      "==================================================\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "144\n",
      "==================================================\n",
      "new date =20171223, type=40004,5112.0,old=4985.0\n",
      "new date =<*>, type=<*>,<*>,old=<*>\n",
      "17\n",
      "==================================================\n",
      "Count : 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "datasets = ['HealthApp']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('-' * 50)\n",
    "    print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "\n",
    "    # tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "    tokenized_logs = [tokenize(log) for log in logs]\n",
    "    print(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n",
    "\n",
    "    # store the logs in the cluster\n",
    "    inputs = []\n",
    "    for i in range(cluster_nums):\n",
    "        inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "    for i, label in enumerate(labels):\n",
    "        inputs[label][0] = label\n",
    "        inputs[label][1].append(logs[i])\n",
    "        inputs[label][2].append(i)\n",
    "        if inputs[label][3] == '':\n",
    "            inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "    clusters = []\n",
    "    for input in inputs:\n",
    "        c = Cluster(*input, remove_duplicate= True)\n",
    "        clusters.append(c)\n",
    "    Count = 0\n",
    "    for c in clusters:    \n",
    "        if len(c.indexs) > 10:\n",
    "            print(c.logs[0])\n",
    "            print(c.oracle_template)\n",
    "            print(len(c.indexs))\n",
    "            print('=' * 50)\n",
    "            Count+=1\n",
    "    print(f'Count : {Count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 75\n",
      "len of templates: 75\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "========================================\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "========================================\n",
      "flush sensor data\n",
      "flush sensor data\n",
      "========================================\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "========================================\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "========================================\n",
      "getBinderPackageName packageName = com.huawei.health\n",
      "getBinderPackageName packageName = com.huawei.health\n",
      "========================================\n",
      "needAutoSync autoSyncSwitch is open\n",
      "needAutoSync autoSyncSwitch is open\n",
      "========================================\n",
      "initDataPrivacy the dataPrivacy switch is open, start push health data!\n",
      "initDataPrivacy the dataPrivacy switch is open, start push health data!\n",
      "========================================\n",
      "initDataPrivacy the dataPrivacy is true\n",
      "initDataPrivacy the dataPrivacy is <*>\n",
      "========================================\n",
      "initUserPrivacy the userPrivacy switch is open, start push user data!\n",
      "initUserPrivacy the userPrivacy switch is open, start push user data!\n",
      "========================================\n",
      "initUserPrivacy the userPrivacy is true\n",
      "initUserPrivacy the userPrivacy is <*>\n",
      "========================================\n",
      "ifCanSync not! no cloud version\n",
      "ifCanSync not! no cloud version\n",
      "========================================\n",
      "sendSyncFailedBroadcast\n",
      "sendSyncFailedBroadcast\n",
      "========================================\n",
      "isScreenOn true\n",
      "isScreenOn <*>\n",
      "========================================\n",
      "screen status unknown,think screen on\n",
      "screen status unknown,think screen on\n",
      "========================================\n",
      "flushTempCacheToDB by stand\n",
      "flushTempCacheToDB by stand\n",
      "========================================\n",
      "getAppContext() isAppValid health or wear, packageName = com.huawei.health\n",
      "getAppContext() isAppValid health or wear, packageName = <*>\n",
      "========================================\n",
      "uploadStaticsToDB failed message=true\n",
      "uploadStaticsToDB failed message=<*>\n",
      "========================================\n",
      "checkInsertStatus stepSum or calorieSum is enough\n",
      "checkInsertStatus stepSum or calorieSum is enough\n",
      "========================================\n",
      "checkInsertStatus stepStatSum or calorieStatSum is enough\n",
      "checkInsertStatus stepStatSum or calorieStatSum is enough\n",
      "========================================\n",
      "setWriteDBLastDataMinute success\n",
      "setWriteDBLastDataMinute success\n",
      "========================================\n",
      "startTimer start autoSync\n",
      "startTimer start autoSync\n",
      "========================================\n",
      "initEnviroument\n",
      "initEnviroument\n",
      "========================================\n",
      "getStepCounterStatus\n",
      "getStepCounterStatus\n",
      "========================================\n",
      " getStepCounterStatus= true\n",
      "getStepCounterStatus= <*>\n",
      "========================================\n",
      "reStartStepCounter\n",
      "reStartStepCounter\n",
      "========================================\n",
      "registersensorsuccess: true\n",
      "registersensorsuccess: <*>\n",
      "========================================\n",
      "clear()\n",
      "clear()\n",
      "========================================\n",
      "tryToRecordAsBasicStepData bWrite true\n",
      "tryToRecordAsBasicStepData bWrite <*>\n",
      "========================================\n",
      "closeNotification...\n",
      "closeNotification...\n",
      "========================================\n",
      "deleteHealthNotification()\n",
      "deleteHealthNotification()\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "clusters = []\n",
    "for input in inputs:\n",
    "    c = Cluster(*input, remove_duplicate= True)\n",
    "    clusters.append(c)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     print(f'cluster {cluster.label}: {len(cluster.logs)} logs, {len(cluster.indexs)} indexs')\n",
    "\n",
    "# num = 27\n",
    "# print('cluster:', num)\n",
    "# print('length:', len(clusters[num].indexs))\n",
    "# print('template:', clusters[num].oracle_template)\n",
    "# print('len of set:', len(clusters[num].logs))\n",
    "# print('-'*20)\n",
    "# for log in clusters[num].logs:\n",
    "#     print(log)\n",
    "# print('='*40)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     if len(set(cluster.logs)) == 1 and not any(char.isdigit() for char in cluster.logs[0]):\n",
    "#         print(f\"{cluster.logs[0]}\\n{cluster.oracle_template}\")\n",
    "#         print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "      <th>N_ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.98577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.0960</td>\n",
       "      <td>0.99836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.99856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>1.6905</td>\n",
       "      <td>0.98900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.99873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>1.0035</td>\n",
       "      <td>0.98262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>5.6115</td>\n",
       "      <td>0.89671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>4.3035</td>\n",
       "      <td>0.92582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>8.2510</td>\n",
       "      <td>0.92283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.99780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>0.98317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>0.99147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>10.0140</td>\n",
       "      <td>0.89214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>2.3054</td>\n",
       "      <td>0.97086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'result_LILAC_2k_32_3_gpt-3.5-turbo-0125', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BGL: group Accuracy: 0.9845, Message-Level Accuracy: 0.8818, Edit Distance: 3.5548\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "\n",
    "evaluate_single_dataset(\n",
    "    'outputs/parser/Test_10shot/BGL_2k.log_structured.csv', 'BGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x1a3', '0X4D2', '0xABCDEF']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\b0[xX][0-9a-fA-F]+\\b'\n",
    "text = \"Here are some hex numbers: 0x1a3, 0X4D2, and 0xABCDEF.\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL ----------------\n",
      "Processing HDFS ----------------\n",
      "Processing Linux ----------------\n",
      "Processing HealthApp ----------------\n",
      "Processing OpenStack ----------------\n",
      "Processing OpenSSH ----------------\n",
      "Processing HPC ----------------\n",
      "Processing Zookeeper ----------------\n",
      "Processing Mac ----------------\n",
      "Processing Hadoop ----------------\n",
      "Processing Android ----------------\n",
      "Processing Windows ----------------\n",
      "Processing Apache ----------------\n",
      "Processing Thunderbird ----------------\n",
      "Processing Spark ----------------\n",
      "1334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count = 0\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Count -- num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4: 15 + 28 + 5 + 18 + 10\n",
    "# 5: 1 + 2\n",
    "# 6: 15 + 28 + 5 + 18 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('connection from 84.102.20.2 () at Sun Jul 24 02:38:22 2005', 'connection from <*> () at <*>'), ('connection from 207.30.238.8 (host8.topspot.net) at Sun Jul 17 12:31:00 2005', 'connection from <*> (<*>) at <*>'), ('User unknown timed out after 900 seconds at Sat Jun 18 02:23:10 2005', 'User unknown timed out after <*> seconds at <*>'), ('Authentication failed from 163.27.187.39 (163.27.187.39): Software caused connection abort', 'Authentication failed from <*> (<*>): Software caused connection abort'), ('authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=61-220-159-99.hinet-ip.hinet.net  user=root', 'authentication failure; logname= uid=<*> euid=<*> tty=<*> ruser= rhost=<*>  user=<*>')]\n"
     ]
    }
   ],
   "source": [
    "from utils.sample import nearest_k_pairs_from_log\n",
    "pairs = [('authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=61-220-159-99.hinet-ip.hinet.net  user=root', 'authentication failure; logname= uid=<*> euid=<*> tty=<*> ruser= rhost=<*>  user=<*>'), ('connection from 207.30.238.8 (host8.topspot.net) at Sun Jul 17 12:31:00 2005', 'connection from <*> (<*>) at <*>'), ('connection from 84.102.20.2 () at Sun Jul 24 02:38:22 2005', 'connection from <*> () at <*>'), ('authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=biblioteka.wsi.edu.pl', 'authentication failure; logname= uid=<*> euid=<*> tty=<*> ruser= rhost=<*>'), ('check pass; user unknown', 'check pass; user unknown'), ('session opened for user cyrus by (uid=0)', 'session opened for user <*> by (uid=<*>)'), ('session closed for user cyrus', 'session closed for user <*>'), ('ALERT exited abnormally with [1]', 'ALERT exited abnormally with [<*>]'), ('Kerberos authentication failed', 'Kerberos authentication failed'), ('notify question section contains no SOA', 'notify question section contains no SOA'), ('Authentication failed from 163.27.187.39 (163.27.187.39): Software caused connection abort', 'Authentication failed from <*> (<*>): Software caused connection abort'), ('Authentication failed from 163.27.187.39 (163.27.187.39): Permission denied in replay cache code', 'Authentication failed from <*> (<*>): Permission denied in replay cache code'), ('restart.', 'restart.'), ('cupsd shutdown succeeded', 'cupsd shutdown succeeded'), ('cupsd startup succeeded', 'cupsd startup succeeded'), (\"removing device node '/udev/vcsa2'\", \"removing device node '<*>'\"), (\"creating device node '/udev/vcs2'\", \"creating device node '<*>'\"), ('getpeername (ftpd): Transport endpoint is not connected', 'getpeername (ftpd): Transport endpoint is not connected'), ('BIOS-e820: 00000000000f0000 - 0000000000100000 (reserved)', '<*>: <*> - <*> (reserved)'), ('ANONYMOUS FTP LOGIN FROM 84.102.20.2,  (anonymous)', 'ANONYMOUS FTP LOGIN FROM <*>,  (anonymous)'), (\"warning: can't get client address: Connection reset by peer\", \"warning: can't get client address: Connection reset by peer\"), ('BIOS-e820: 0000000000000000 - 00000000000a0000 (usable)', '<*>: <*> - <*> (usable)'), \n",
    "('User unknown timed out after 900 seconds at Sat Jun 18 02:23:10 2005', 'User unknown timed out after <*> seconds at <*>'), ('Received SNMP packet(s) from 67.170.148.126', 'Received SNMP packet(s) from <*>'), ('*** info [mice.c(1766)]:', '*** info [mice.c(<*>)]:'), ('imps2: Auto-detected intellimouse PS/2', '<*>: Auto-detected intellimouse <*>'), ('session opened for user root by LOGIN(uid=0)', 'session opened for user <*> by LOGIN(uid=<*>)'), ('ROOT LOGIN ON tty2', 'ROOT LOGIN ON <*>'), (\"Couldn't authenticate user\", \"Couldn't authenticate user\"), ('syslogd startup succeeded', 'syslogd startup succeeded'), ('klogd 1.4.1, log source = /proc/kmsg started.', 'klogd <*>, log source = <*> started.'), ('Linux version 2.6.5-1.358 (bhcompile@bugs.build.redhat.com) (gcc version 3.3.3 20040412 (Red Hat Linux 3.3.3-7)) #1 Sat May 8 09:04:50 EDT 2004', 'Linux version <*> (<*>) (gcc version <*> <*> (Red Hat Linux <*>)) <*> <*> <*> <*> <*> EDT <*>')]\n",
    "print(nearest_k_pairs_from_log('connection from 61.74.96.178 () at Wed Jun 29 03:22:22 2005', pairs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256\n",
      "1255\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 存储解析后的日志列表\n",
    "log_lists = []\n",
    "\n",
    "# 逐行读取文件并解析每行的 JSON 数据\n",
    "with open('cost_lilac_32_3.json', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == '[':\n",
    "            list_str = ''\n",
    "            start_load = True\n",
    "        if line.strip() == ']':\n",
    "            list_str += line\n",
    "            log_list = json.loads(list_str)\n",
    "            log_lists.append(log_list)\n",
    "            start_load = False\n",
    "        if start_load:\n",
    "            list_str += line\n",
    "\n",
    "# 将小列表转换为不可变的元组来进行去重\n",
    "\n",
    "print(len(log_lists))\n",
    "def make_hashable(log_list):\n",
    "    return tuple(tuple(sorted(d.items())) for d in log_list)\n",
    "\n",
    "\n",
    "# 去重\n",
    "unique_lists = list(set(make_hashable(log_list) for log_list in log_lists\n",
    "))\n",
    "\n",
    "# 将元组转换回列表\n",
    "unique_big_list = [list(map(dict, log_list)) for log_list in unique_lists]\n",
    "\n",
    "print(len(unique_big_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
