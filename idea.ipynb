{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "datasets = ['BGL']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('-' * 50)\n",
    "    print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "\n",
    "    # tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "    tokenized_logs = [tokenize(log) for log in logs]\n",
    "    print(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n",
    "\n",
    "    # store the logs in the cluster\n",
    "    # inputs = []\n",
    "    # for i in range(cluster_nums):\n",
    "    #     inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "    # for i, label in enumerate(labels):\n",
    "    #     inputs[label][0] = label\n",
    "    #     inputs[label][1].append(logs[i])\n",
    "    #     inputs[label][2].append(i)\n",
    "    #     if inputs[label][3] == '':\n",
    "    #         inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "    # clusters = []\n",
    "    # for input in inputs:\n",
    "    #     c = Cluster(*input, remove_duplicate= True)\n",
    "    #     clusters.append(c)\n",
    "    # Count = 0\n",
    "    # for c in clusters:    \n",
    "    #     if len(c.indexs) > 10:\n",
    "    #         print(c.logs[0])\n",
    "    #         print(c.oracle_template)\n",
    "    #         print(len(c.indexs))\n",
    "    #         print('=' * 50)\n",
    "    #         Count+=1\n",
    "    # print(f'Count : {Count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "clusters = []\n",
    "for input in inputs:\n",
    "    c = Cluster(*input, remove_duplicate= True)\n",
    "    clusters.append(c)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     print(f'cluster {cluster.label}: {len(cluster.logs)} logs, {len(cluster.indexs)} indexs')\n",
    "\n",
    "num = 1\n",
    "print('cluster:', num)\n",
    "print('length:', len(clusters[num].indexs))\n",
    "print('template:', clusters[num].oracle_template)\n",
    "set_logs = set(clusters[num].static_logs)\n",
    "print('len of set:', len(set_logs))\n",
    "print('-'*20)\n",
    "for log in set_logs:\n",
    "    print(log)\n",
    "print('='*40)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     if len(set(cluster.logs)) == 1 and not any(char.isdigit() for char in cluster.logs[0]):\n",
    "#         print(f\"{cluster.logs[0]}\\n{cluster.oracle_template}\")\n",
    "#         print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000, Normalized Edit Distance: 1.000000\n",
      "      Hadoop: group Accuracy: 0.9885, Message-Level Accuracy: 0.8850, Edit Distance: 6.6165, Normalized Edit Distance: 0.951579\n",
      "       Spark: group Accuracy: 0.9790, Message-Level Accuracy: 0.9535, Edit Distance: 0.4600, Normalized Edit Distance: 0.987549\n",
      "   Zookeeper: group Accuracy: 0.9745, Message-Level Accuracy: 0.8340, Edit Distance: 1.9040, Normalized Edit Distance: 0.933939\n",
      "         BGL: group Accuracy: 0.9925, Message-Level Accuracy: 0.9455, Edit Distance: 1.8415, Normalized Edit Distance: 0.988423\n",
      "         HPC: group Accuracy: 0.9525, Message-Level Accuracy: 0.9370, Edit Distance: 0.4215, Normalized Edit Distance: 0.994895\n",
      " Thunderbird: group Accuracy: 0.9190, Message-Level Accuracy: 0.8585, Edit Distance: 2.0180, Normalized Edit Distance: 0.953605\n",
      "     Windows: group Accuracy: 0.9960, Message-Level Accuracy: 0.6075, Edit Distance: 9.0435, Normalized Edit Distance: 0.861319\n",
      "       Linux: group Accuracy: 0.9960, Message-Level Accuracy: 0.2755, Edit Distance: 9.6370, Normalized Edit Distance: 0.810824\n",
      "     Android: group Accuracy: 0.8360, Message-Level Accuracy: 0.7725, Edit Distance: 4.4225, Normalized Edit Distance: 0.944230\n",
      "   HealthApp: group Accuracy: 0.9950, Message-Level Accuracy: 0.9900, Edit Distance: 0.2830, Normalized Edit Distance: 0.995434\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 0.9780, Edit Distance: 0.2300, Normalized Edit Distance: 0.996156\n",
      "     OpenSSH: group Accuracy: 1.0000, Message-Level Accuracy: 0.9755, Edit Distance: 1.0610, Normalized Edit Distance: 0.989056\n",
      "   OpenStack: group Accuracy: 1.0000, Message-Level Accuracy: 0.9925, Edit Distance: 0.0225, Normalized Edit Distance: 0.999824\n",
      "         Mac: group Accuracy: 0.8380, Message-Level Accuracy: 0.5435, Edit Distance: 10.1340, Normalized Edit Distance: 0.888705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "      <th>N_ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>6.6165</td>\n",
       "      <td>0.95158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.98755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>1.9040</td>\n",
       "      <td>0.93394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>1.8415</td>\n",
       "      <td>0.98842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.99489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>2.0180</td>\n",
       "      <td>0.95360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>9.0435</td>\n",
       "      <td>0.86132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>9.6370</td>\n",
       "      <td>0.81082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>4.4225</td>\n",
       "      <td>0.94423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.99543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.99616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>1.0610</td>\n",
       "      <td>0.98906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.99982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>10.1340</td>\n",
       "      <td>0.88870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>3.2063</td>\n",
       "      <td>0.95304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'LogBatcher_0shot_32candidate_10batchsize_with_smilarity_sample', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "datasets = ['BGL', 'HDFS', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper']\n",
    "for dataset in datasets:\n",
    "    evaluate_single_dataset(\n",
    "        f'outputs/parser/Test_10shot_with_pruning/{dataset}_2k.log_structured.csv', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count = 0\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Caclulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_prompt_tokens(prompt, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 计算编码后的token数\n",
    "    prompt_tokens = encoder.encode(prompt)\n",
    "    return len(prompt_tokens)\n",
    "\n",
    "\n",
    "def count_message_tokens(messages, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 初始化token计数\n",
    "    token_count = 0\n",
    "\n",
    "    # 计算每个消息的token数\n",
    "    for message in messages:\n",
    "        role_tokens = encoder.encode(message['role'])\n",
    "        content_tokens = encoder.encode(message['content'])\n",
    "        token_count += len(role_tokens) + \\\n",
    "            len(content_tokens) + 4  # 加上特殊的消息分隔符的token数\n",
    "\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs[dataset] = df['Content'].tolist()\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "for log in logs['HealthApp']:\n",
    "    log = log.strip()\n",
    "\n",
    "# 存储解析后的日志列表\n",
    "message_list = []\n",
    "# load every message\n",
    "file = 'cost_lilac_32_3.json'\n",
    "with open('outputs/cost/LogBatcher_3shot_32candidate_10batchsize.json', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == '[':\n",
    "            list_str = ''\n",
    "            start_load = True\n",
    "        if line.strip() == ']':\n",
    "            list_str += line\n",
    "            message = json.loads(list_str)\n",
    "            message_list.append(message)\n",
    "            start_load = False\n",
    "        if start_load:\n",
    "            list_str += line\n",
    "# print(len(message_list))\n",
    "for message in message_list:\n",
    "    # for LILAC\n",
    "    log = message[-1]['content'].split('\\n')[0].replace('Log message: `', '').replace('`', '')\n",
    "    # for LogBatcher\n",
    "    # log = message[-1]['content'].split('\\n')[0] \n",
    "    # print(log)\n",
    "    for dataset in datasets:\n",
    "        if log in logs[dataset]:\n",
    "            counts_token[dataset] += count_message_tokens(message, 'gpt-3.5-turbo')\n",
    "            counts_message[dataset] += 1\n",
    "            break\n",
    "        if dataset == 'Mac':\n",
    "            print(log)\n",
    "for dataset in datasets:\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset]  )\n",
    "\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))\n",
    "\n",
    "# remove the same log messages\n",
    "\n",
    "# def make_hashable(log_list):\n",
    "\n",
    "#     return tuple(tuple(sorted(d.items())) for d in log_list)\n",
    "# unique_lists = list(set(make_hashable(log_list) for log_list in message_list))\n",
    "\n",
    "# unique_big_list = [list(map(dict, log_list)) for log_list in unique_lists]\n",
    "# print(len(unique_big_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "# datasets = ['HDFS']\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "    with open(f'DivLog/cost/cost_divlog_for_{dataset}.json', 'r') as file:\n",
    "        prompt_list = json.load(file)\n",
    "    # print(f\"caculate {dataset}: len: {len(prompt_list)}\")\n",
    "    for prompt in prompt_list:\n",
    "        counts_token[dataset] += count_prompt_tokens(prompt, 'gpt-3.5-turbo')\n",
    "        counts_message[dataset] += 1\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset])\n",
    "\n",
    "# print average token count\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_prompt_tokens('For each log after <prompt> tag, extract one log template(substitute variable tokens in the log as <*> and remain constant tokens to construct the template)and put the template after <extraction> tag and between <START> and <END> tags.', 'gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample_byword import extract_variables\n",
    "print(extract_variables(\"488205 floating point alignment exceptions\",\n",
    "      \"<*> floating point alignment exceptions\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,2,3,4,5]\n",
    "class test:\n",
    "    def __init__(self):\n",
    "        self.list2 = [1,2,3,4,7]\n",
    "\n",
    "t_class = test()\n",
    "for a in list1:\n",
    "    if a == 4:\n",
    "        t_class.list2.remove(a)\n",
    "print(t_class.list2)\n",
    "print(list1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
