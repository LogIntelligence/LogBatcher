{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "datasets = ['HealthApp']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('-' * 50)\n",
    "    print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "\n",
    "    # tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "    tokenized_logs = [tokenize(log) for log in logs]\n",
    "    print(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n",
    "\n",
    "    # store the logs in the cluster\n",
    "    inputs = []\n",
    "    for i in range(cluster_nums):\n",
    "        inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "    for i, label in enumerate(labels):\n",
    "        inputs[label][0] = label\n",
    "        inputs[label][1].append(logs[i])\n",
    "        inputs[label][2].append(i)\n",
    "        if inputs[label][3] == '':\n",
    "            inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "    clusters = []\n",
    "    for input in inputs:\n",
    "        c = Cluster(*input, remove_duplicate= True)\n",
    "        clusters.append(c)\n",
    "    Count = 0\n",
    "    for c in clusters:    \n",
    "        if len(c.indexs) > 10:\n",
    "            print(c.logs[0])\n",
    "            print(c.oracle_template)\n",
    "            print(len(c.indexs))\n",
    "            print('=' * 50)\n",
    "            Count+=1\n",
    "    print(f'Count : {Count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "clusters = []\n",
    "for input in inputs:\n",
    "    c = Cluster(*input, remove_duplicate= True)\n",
    "    clusters.append(c)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     print(f'cluster {cluster.label}: {len(cluster.logs)} logs, {len(cluster.indexs)} indexs')\n",
    "\n",
    "# num = 27\n",
    "# print('cluster:', num)\n",
    "# print('length:', len(clusters[num].indexs))\n",
    "# print('template:', clusters[num].oracle_template)\n",
    "# print('len of set:', len(clusters[num].logs))\n",
    "# print('-'*20)\n",
    "# for log in clusters[num].logs:\n",
    "#     print(log)\n",
    "# print('='*40)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     if len(set(cluster.logs)) == 1 and not any(char.isdigit() for char in cluster.logs[0]):\n",
    "#         print(f\"{cluster.logs[0]}\\n{cluster.oracle_template}\")\n",
    "#         print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000, Normalized Edit Distance: 1.000000\n",
      "      Hadoop: group Accuracy: 0.9910, Message-Level Accuracy: 0.9610, Edit Distance: 1.0850, Normalized Edit Distance: 0.988421\n",
      "       Spark: group Accuracy: 0.9245, Message-Level Accuracy: 0.8825, Edit Distance: 1.8290, Normalized Edit Distance: 0.970398\n",
      "   Zookeeper: group Accuracy: 0.9885, Message-Level Accuracy: 0.9875, Edit Distance: 0.1705, Normalized Edit Distance: 0.997280\n",
      "         BGL: group Accuracy: 0.9950, Message-Level Accuracy: 0.9645, Edit Distance: 1.7440, Normalized Edit Distance: 0.989579\n",
      "         HPC: group Accuracy: 0.9525, Message-Level Accuracy: 0.9265, Edit Distance: 0.6450, Normalized Edit Distance: 0.992882\n",
      " Thunderbird: group Accuracy: 0.7045, Message-Level Accuracy: 0.9230, Edit Distance: 0.7875, Normalized Edit Distance: 0.985225\n",
      "     Windows: group Accuracy: 0.6915, Message-Level Accuracy: 0.4540, Edit Distance: 12.1435, Normalized Edit Distance: 0.806458\n",
      "       Linux: group Accuracy: 0.9400, Message-Level Accuracy: 0.9225, Edit Distance: 0.5845, Normalized Edit Distance: 0.978425\n",
      "     Android: group Accuracy: 0.9730, Message-Level Accuracy: 0.7925, Edit Distance: 3.7485, Normalized Edit Distance: 0.957457\n",
      "   HealthApp: group Accuracy: 0.9025, Message-Level Accuracy: 0.8870, Edit Distance: 1.1140, Normalized Edit Distance: 0.980997\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000, Normalized Edit Distance: 1.000000\n",
      "     OpenSSH: group Accuracy: 1.0000, Message-Level Accuracy: 0.6525, Edit Distance: 2.5980, Normalized Edit Distance: 0.966316\n",
      "   OpenStack: group Accuracy: 1.0000, Message-Level Accuracy: 0.9190, Edit Distance: 0.8365, Normalized Edit Distance: 0.990221\n",
      "         Mac: group Accuracy: 0.8120, Message-Level Accuracy: 0.5270, Edit Distance: 15.8585, Normalized Edit Distance: 0.878788\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "      <th>N_ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>1.0850</td>\n",
       "      <td>0.98842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>1.8290</td>\n",
       "      <td>0.97040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.99728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>1.7440</td>\n",
       "      <td>0.98958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.99288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.98522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>12.1435</td>\n",
       "      <td>0.80646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.97843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>3.7485</td>\n",
       "      <td>0.95746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>1.1140</td>\n",
       "      <td>0.98100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>2.5980</td>\n",
       "      <td>0.96632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>0.99022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>15.8585</td>\n",
       "      <td>0.87879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>2.8763</td>\n",
       "      <td>0.96550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'LogBatcher_0shot_32candidate_10batchsize_meta-llama_Llama-3-70b-chat-hf', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "datasets = ['BGL', 'HDFS', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper']\n",
    "for dataset in datasets:\n",
    "    evaluate_single_dataset(\n",
    "        f'outputs/parser/Test_10shot_with_pruning/{dataset}_2k.log_structured.csv', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count = 0\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Caclulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_prompt_tokens(prompt, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 计算编码后的token数\n",
    "    prompt_tokens = encoder.encode(prompt)\n",
    "    return len(prompt_tokens)\n",
    "\n",
    "\n",
    "def count_message_tokens(messages, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 初始化token计数\n",
    "    token_count = 0\n",
    "\n",
    "    # 计算每个消息的token数\n",
    "    for message in messages:\n",
    "        role_tokens = encoder.encode(message['role'])\n",
    "        content_tokens = encoder.encode(message['content'])\n",
    "        token_count += len(role_tokens) + \\\n",
    "            len(content_tokens) + 4  # 加上特殊的消息分隔符的token数\n",
    "\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs[dataset] = df['Content'].tolist()\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "for log in logs['HealthApp']:\n",
    "    log = log.strip()\n",
    "\n",
    "# 存储解析后的日志列表\n",
    "message_list = []\n",
    "# load every message\n",
    "file = 'cost_lilac_32_3.json'\n",
    "with open('outputs/cost/LogBatcher_3shot_32candidate_10batchsize.json', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == '[':\n",
    "            list_str = ''\n",
    "            start_load = True\n",
    "        if line.strip() == ']':\n",
    "            list_str += line\n",
    "            message = json.loads(list_str)\n",
    "            message_list.append(message)\n",
    "            start_load = False\n",
    "        if start_load:\n",
    "            list_str += line\n",
    "# print(len(message_list))\n",
    "for message in message_list:\n",
    "    # for LILAC\n",
    "    log = message[-1]['content'].split('\\n')[0].replace('Log message: `', '').replace('`', '')\n",
    "    # for LogBatcher\n",
    "    # log = message[-1]['content'].split('\\n')[0] \n",
    "    # print(log)\n",
    "    for dataset in datasets:\n",
    "        if log in logs[dataset]:\n",
    "            counts_token[dataset] += count_message_tokens(message, 'gpt-3.5-turbo')\n",
    "            counts_message[dataset] += 1\n",
    "            break\n",
    "        if dataset == 'Mac':\n",
    "            print(log)\n",
    "for dataset in datasets:\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset]  )\n",
    "\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))\n",
    "\n",
    "# remove the same log messages\n",
    "\n",
    "# def make_hashable(log_list):\n",
    "\n",
    "#     return tuple(tuple(sorted(d.items())) for d in log_list)\n",
    "# unique_lists = list(set(make_hashable(log_list) for log_list in message_list))\n",
    "\n",
    "# unique_big_list = [list(map(dict, log_list)) for log_list in unique_lists]\n",
    "# print(len(unique_big_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353.3445\n",
      "245.6495\n",
      "204.527\n",
      "180.279\n",
      "210.173\n",
      "144.477\n",
      "261.2915\n",
      "230.9235\n",
      "222.2085\n",
      "215.33\n",
      "175.8405\n",
      "182.304\n",
      "245.3635\n",
      "343.0185\n",
      "290.645\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(counts_token[dataset] \u001b[38;5;241m/\u001b[39m counts_message[dataset])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print average token count\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcounts_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28msum\u001b[39m(counts_token\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(counts_message\u001b[38;5;241m.\u001b[39mvalues()))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "# datasets = ['HDFS']\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "    with open(f'DivLog/cost/cost_divlog_for_{dataset}.json', 'r') as file:\n",
    "        prompt_list = json.load(file)\n",
    "    # print(f\"caculate {dataset}: len: {len(prompt_list)}\")\n",
    "    for prompt in prompt_list:\n",
    "        counts_token[dataset] += count_prompt_tokens(prompt, 'gpt-3.5-turbo')\n",
    "        counts_message[dataset] += 1\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset])\n",
    "\n",
    "# print average token count\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(count_prompt_tokens('For each log after <prompt> tag, extract one log template(substitute variable tokens in the log as <*> and remain constant tokens to construct the template)and put the template after <extraction> tag and between <START> and <END> tags.', 'gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('488205',)\n"
     ]
    }
   ],
   "source": [
    "from utils.sample_byword import extract_variables\n",
    "print(extract_variables(\"488205 floating point alignment exceptions\",\n",
    "      \"<*> floating point alignment exceptions\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 7]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "list1 = [1,2,3,4,5]\n",
    "class test:\n",
    "    def __init__(self):\n",
    "        self.list2 = [1,2,3,4,7]\n",
    "\n",
    "t_class = test()\n",
    "for a in list1:\n",
    "    if a == 4:\n",
    "        t_class.list2.remove(a)\n",
    "print(t_class.list2)\n",
    "print(list1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
