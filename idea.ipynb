{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering HealthApp dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "dataset = 'HealthApp'\n",
    "print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "logs = df['Content'].tolist()\n",
    "templates = df['EventTemplate'].tolist()\n",
    "\n",
    "# tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "tokenized_logs = [tokenize(log) for log in logs]\n",
    "labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 75\n",
      "len of templates: 75\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "onReceive action: android.intent.action.SCREEN_ON\n",
      "========================================\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "processHandleBroadcastAction action:android.intent.action.SCREEN_ON\n",
      "========================================\n",
      "flush sensor data\n",
      "flush sensor data\n",
      "========================================\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "onReceive action: android.intent.action.SCREEN_OFF\n",
      "========================================\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "processHandleBroadcastAction action:android.intent.action.TIME_TICK\n",
      "========================================\n",
      "getBinderPackageName packageName = com.huawei.health\n",
      "getBinderPackageName packageName = com.huawei.health\n",
      "========================================\n",
      "needAutoSync autoSyncSwitch is open\n",
      "needAutoSync autoSyncSwitch is open\n",
      "========================================\n",
      "initDataPrivacy the dataPrivacy switch is open, start push health data!\n",
      "initDataPrivacy the dataPrivacy switch is open, start push health data!\n",
      "========================================\n",
      "initDataPrivacy the dataPrivacy is true\n",
      "initDataPrivacy the dataPrivacy is <*>\n",
      "========================================\n",
      "initUserPrivacy the userPrivacy switch is open, start push user data!\n",
      "initUserPrivacy the userPrivacy switch is open, start push user data!\n",
      "========================================\n",
      "initUserPrivacy the userPrivacy is true\n",
      "initUserPrivacy the userPrivacy is <*>\n",
      "========================================\n",
      "ifCanSync not! no cloud version\n",
      "ifCanSync not! no cloud version\n",
      "========================================\n",
      "sendSyncFailedBroadcast\n",
      "sendSyncFailedBroadcast\n",
      "========================================\n",
      "isScreenOn true\n",
      "isScreenOn <*>\n",
      "========================================\n",
      "screen status unknown,think screen on\n",
      "screen status unknown,think screen on\n",
      "========================================\n",
      "flushTempCacheToDB by stand\n",
      "flushTempCacheToDB by stand\n",
      "========================================\n",
      "getAppContext() isAppValid health or wear, packageName = com.huawei.health\n",
      "getAppContext() isAppValid health or wear, packageName = <*>\n",
      "========================================\n",
      "uploadStaticsToDB failed message=true\n",
      "uploadStaticsToDB failed message=<*>\n",
      "========================================\n",
      "checkInsertStatus stepSum or calorieSum is enough\n",
      "checkInsertStatus stepSum or calorieSum is enough\n",
      "========================================\n",
      "checkInsertStatus stepStatSum or calorieStatSum is enough\n",
      "checkInsertStatus stepStatSum or calorieStatSum is enough\n",
      "========================================\n",
      "setWriteDBLastDataMinute success\n",
      "setWriteDBLastDataMinute success\n",
      "========================================\n",
      "startTimer start autoSync\n",
      "startTimer start autoSync\n",
      "========================================\n",
      "initEnviroument\n",
      "initEnviroument\n",
      "========================================\n",
      "getStepCounterStatus\n",
      "getStepCounterStatus\n",
      "========================================\n",
      " getStepCounterStatus= true\n",
      "getStepCounterStatus= <*>\n",
      "========================================\n",
      "reStartStepCounter\n",
      "reStartStepCounter\n",
      "========================================\n",
      "registersensorsuccess: true\n",
      "registersensorsuccess: <*>\n",
      "========================================\n",
      "clear()\n",
      "clear()\n",
      "========================================\n",
      "tryToRecordAsBasicStepData bWrite true\n",
      "tryToRecordAsBasicStepData bWrite <*>\n",
      "========================================\n",
      "closeNotification...\n",
      "closeNotification...\n",
      "========================================\n",
      "deleteHealthNotification()\n",
      "deleteHealthNotification()\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "clusters = []\n",
    "for input in inputs:\n",
    "    c = Cluster(*input, remove_duplicate= True)\n",
    "    clusters.append(c)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     print(f'cluster {cluster.label}: {len(cluster.logs)} logs, {len(cluster.indexs)} indexs')\n",
    "\n",
    "# num = 27\n",
    "# print('cluster:', num)\n",
    "# print('length:', len(clusters[num].indexs))\n",
    "# print('template:', clusters[num].oracle_template)\n",
    "# print('len of set:', len(clusters[num].logs))\n",
    "# print('-'*20)\n",
    "# for log in clusters[num].logs:\n",
    "#     print(log)\n",
    "# print('='*40)\n",
    "\n",
    "for cluster in clusters:\n",
    "    if len(set(cluster.logs)) == 1 and not any(char.isdigit() for char in cluster.logs[0]):\n",
    "        print(f\"{cluster.logs[0]}\\n{cluster.oracle_template}\")\n",
    "        print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000\n",
      "      Hadoop: group Accuracy: 0.9890, Message-Level Accuracy: 0.8765, Edit Distance: 6.6965\n",
      "       Spark: group Accuracy: 0.9964, Message-Level Accuracy: 0.9918, Edit Distance: 0.1734\n",
      "   Zookeeper: group Accuracy: 0.9930, Message-Level Accuracy: 0.9890, Edit Distance: 0.2205\n",
      "         BGL: group Accuracy: 0.9805, Message-Level Accuracy: 0.9075, Edit Distance: 3.5035\n",
      "         HPC: group Accuracy: 0.9463, Message-Level Accuracy: 0.9311, Edit Distance: 0.3831\n",
      " Thunderbird: group Accuracy: 0.8873, Message-Level Accuracy: 0.8137, Edit Distance: 5.3796\n",
      "     Windows: group Accuracy: 1.0000, Message-Level Accuracy: 0.6073, Edit Distance: 12.0125\n",
      "       Linux: group Accuracy: 0.9360, Message-Level Accuracy: 0.7730, Edit Distance: 0.7855\n",
      "     Android: group Accuracy: 0.9405, Message-Level Accuracy: 0.7870, Edit Distance: 1.9710\n",
      "   HealthApp: group Accuracy: 0.9865, Message-Level Accuracy: 0.9775, Edit Distance: 0.6330\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 0.9840, Edit Distance: 0.2240\n",
      "     OpenSSH: group Accuracy: 0.9765, Message-Level Accuracy: 0.9710, Edit Distance: 1.0680\n",
      "   OpenStack: group Accuracy: 1.0000, Message-Level Accuracy: 0.9925, Edit Distance: 0.0225\n",
      "         Mac: group Accuracy: 0.7845, Message-Level Accuracy: 0.4707, Edit Distance: 16.6184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.876</td>\n",
       "      <td>6.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.908</td>\n",
       "      <td>3.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.814</td>\n",
       "      <td>5.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.607</td>\n",
       "      <td>12.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.971</td>\n",
       "      <td>1.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.471</td>\n",
       "      <td>16.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.872</td>\n",
       "      <td>3.313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'Test_10shot', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BGL: group Accuracy: 0.9845, Message-Level Accuracy: 0.8818, Edit Distance: 3.5548\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "\n",
    "evaluate_single_dataset(\n",
    "    'outputs/parser/Test_10shot/BGL_2k.log_structured.csv', 'BGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x1a3', '0X4D2', '0xABCDEF']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\b0[xX][0-9a-fA-F]+\\b'\n",
    "text = \"Here are some hex numbers: 0x1a3, 0X4D2, and 0xABCDEF.\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL ----------------\n",
      "Processing HDFS ----------------\n",
      "Processing Linux ----------------\n",
      "authentication failure; logname= uid=<*> euid=<*> tty=<*> ruser= rhost=<*>  user=<*>\n",
      "authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root\n",
      "--------------------\n",
      "ANONYMOUS FTP LOGIN FROM <*>,  (anonymous)\n",
      "ANONYMOUS FTP LOGIN FROM 84.102.20.2,  (anonymous)\n",
      "--------------------\n",
      "SELinux:  Initializing.\n",
      "SELinux:  Initializing.\n",
      "--------------------\n",
      "SELinux:  Starting in permissive mode\n",
      "SELinux:  Starting in permissive mode\n",
      "--------------------\n",
      "<*>:  Registering secondary module capability\n",
      "selinux_register_security:  Registering secondary module capability\n",
      "--------------------\n",
      "Initializing random number generator:  succeeded\n",
      "Initializing random number generator:  succeeded\n",
      "--------------------\n",
      "Starting pcmcia:  succeeded\n",
      "Starting pcmcia:  succeeded\n",
      "--------------------\n",
      "Setting network parameters:  succeeded\n",
      "Setting network parameters:  succeeded\n",
      "--------------------\n",
      "Bringing up loopback interface:  succeeded\n",
      "Bringing up loopback interface:  succeeded\n",
      "--------------------\n",
      "SELinux:  Registering netfilter hooks\n",
      "SELinux:  Registering netfilter hooks\n",
      "--------------------\n",
      "Processing HealthApp ----------------\n",
      "Processing OpenStack ----------------\n",
      "Processing OpenSSH ----------------\n",
      "Processing Proxifier ----------------\n",
      "Processing HPC ----------------\n",
      "Processing Zookeeper ----------------\n",
      "Processing Mac ----------------\n",
      "Processing Hadoop ----------------\n",
      "Processing Android ----------------\n",
      "Processing Windows ----------------\n",
      "Processing Apache ----------------\n",
      "Processing Thunderbird ----------------\n",
      "Processing Spark ----------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates and '  ' in template:\n",
    "            count_templates.append(template)\n",
    "            print(template)\n",
    "            print(log)\n",
    "            print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demonstrations_sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Count -- num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4: 15 + 28 + 5 + 18 + 10\n",
    "# 5: 1 + 2\n",
    "# 6: 15 + 28 + 5 + 18 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import tokenize\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "a,b = 0,0\n",
    "pattern = r'^[a-zA-Z]+[0-9]+$'\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    list_log = []\n",
    "    list_tmp = []\n",
    "    print('-'*20)\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    logs = df['Content'].tolist()\n",
    "    freq = Counter(templates)\n",
    "    \n",
    "    for template,log in zip(templates,logs):\n",
    "        tokens = template.split()\n",
    "        for token in tokens:\n",
    "            if ':' in token and '<*>' in token:\n",
    "                # print(f\"{template}\\n{log}\\n{'-'*20}\")\n",
    "                list_tmp.append(template)\n",
    "                list_log.append(log)\n",
    "                break\n",
    "            \n",
    "    for tmp in list_tmp:\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "\n",
    "            'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "# datasets = ['Linux']\n",
    "\n",
    "count_list = []\n",
    "shot = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset...\")\n",
    "    with open (f'outputs/parser/Test/{dataset}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    Read = False\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if 'len=' in line and 'cluster' in line:\n",
    "            if count > 5:\n",
    "                print(length)\n",
    "                for tmp in tmp_list:\n",
    "                    print(tmp.strip('\\n'))\n",
    "                shot+=1\n",
    "            count = 0\n",
    "            tmp_list = []\n",
    "            parts = line.strip().split(\"len=\")\n",
    "            if len(parts) == 2:  # 确保字符串中包含\"len=\"\n",
    "                tmp = parts[1]\n",
    "                length = int(tmp)\n",
    "            if length > 50:\n",
    "                Read = True\n",
    "            else:\n",
    "                Read = False\n",
    "        else:\n",
    "            if Read:\n",
    "                tmp_list.append(line)\n",
    "                # print(line)\n",
    "                count += 1\n",
    "\n",
    "print(shot/len(datasets))\n",
    "# [147, 49, 156, 98, 65, 202, 45, 61, 82, 361, 143, 164, 93, 43, 203, 69]\n",
    "# [137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
