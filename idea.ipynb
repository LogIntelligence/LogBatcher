{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "批量处理\n",
    "\n",
    "1. try some tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Develop\\anaconda\\envs\\langchain38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "d:\\Develop\\anaconda\\envs\\langchain38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def tokenize(log_content):\n",
    "    words = log_content.split()\n",
    "    words = [word for word in words if not re.search(r'\\d', word)]\n",
    "    return words\n",
    "\n",
    "\n",
    "def vectorize(tokenized_logs):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "    return vectorizer.fit_transform(tokenized_logs)\n",
    "\n",
    "\n",
    "def cluster(vectorized_logs, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(vectorized_logs)\n",
    "    return kmeans.labels_\n",
    "\n",
    "\n",
    "# 读取CSV文件\n",
    "dataset = 'Proxifier'\n",
    "df = pd.read_csv(\n",
    "    f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "\n",
    "# 选择某一列，例如'column_name'\n",
    "column = df['Content']\n",
    "\n",
    "# 将该列转换为列表\n",
    "column_list = column.tolist()\n",
    "\n",
    "tokenized_logs = [tokenize(content) for content in column_list]\n",
    "\n",
    "\n",
    "labels = cluster(vectorize(tokenized_logs), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i, l in enumerate(labels):\n",
    "    if l == 6:  # 12, 14 , 17, 29是异常的模板\n",
    "        # print(column_list[i])\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Develop\\anaconda\\envs\\langchain38\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "dataset = 'Proxifier'\n",
    "df = pd.read_csv(\n",
    "    f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "\n",
    "# 选择某一列，例如'column_name'\n",
    "column = df['Content']\n",
    "\n",
    "# 将该列转换为列表\n",
    "column_list = column.tolist()\n",
    "\n",
    "# 特征提取\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(column_list)\n",
    "\n",
    "n = 16\n",
    "# 聚类\n",
    "kmeans = KMeans(n_clusters=n)  # n是模板的数量\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 输出每个log message的分组结果\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示每一批分组情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formi.baidu.com:843 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "127.0.0.1:135 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "127.0.0.1:135 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "203.205.129.102:8080 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "update.hicloud.com:8180 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "local-p2p.qq.com:443 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 503\n",
      "local-p2p.qq.com:443 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 503\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "qd-update.qq.com:8080 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "mtalk.google.com:5228 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "i2.itc.cn:80 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 503\n",
      "qd-update.qq.com:8080 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "qd-update.qq.com:8080 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy server cannot establish a connection with the target, status code 403\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i,l in enumerate(labels):\n",
    "    if l == 3:  # 12, 14 , 17, 29是异常的模板\n",
    "        print(column_list[i])\n",
    "        num +=1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过三个参数选取最合适的n值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "dataset = 'Proxifier'\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "\n",
    "# 选择某一列，例如'column_name'\n",
    "column = df['Content']\n",
    "\n",
    "# 将该列转换为列表\n",
    "column_list = column.tolist()\n",
    "\n",
    "# 特征提取\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(column_list)\n",
    "\n",
    "# 聚类误差\n",
    "errors = []\n",
    "\n",
    "# 轮廓系数\n",
    "silhouettes = []\n",
    "\n",
    "# Calinski-Harabasz指数\n",
    "calinski_harabasz_scores = []\n",
    "\n",
    "# 模板数量的范围\n",
    "range_n_clusters = range(2, 20)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # 聚类\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    # 计算聚类误差\n",
    "    error = kmeans.inertia_\n",
    "    errors.append(error)\n",
    "\n",
    "    # 计算轮廓系数\n",
    "    silhouette = silhouette_score(X, kmeans.labels_)\n",
    "    silhouettes.append(silhouette)\n",
    "\n",
    "    # 计算Calinski-Harabasz指数\n",
    "    calinski_harabasz = calinski_harabasz_score(X.toarray(), kmeans.labels_)\n",
    "    calinski_harabasz_scores.append(calinski_harabasz)\n",
    "\n",
    "# 绘制聚类误差图\n",
    "plt.figure()\n",
    "plt.plot(range_n_clusters, errors, 'o-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Cluster error')\n",
    "plt.title('The Elbow Method')\n",
    "plt.show()\n",
    "\n",
    "# 绘制轮廓系数图\n",
    "plt.figure()\n",
    "plt.plot(range_n_clusters, silhouettes, 'o-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.title('The Silhouette Method')\n",
    "plt.show()\n",
    "\n",
    "# 绘制Calinski-Harabasz指数图\n",
    "plt.figure()\n",
    "plt.plot(range_n_clusters, calinski_harabasz_scores, 'o-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Calinski-Harabasz Index')\n",
    "plt.title('The Calinski-Harabasz Method')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
