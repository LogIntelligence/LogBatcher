{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Proxifier dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyi\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "# select the dataset\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# num_list = []\n",
    "# datasets = ['OpenStack']\n",
    "# for dataset in datasets:\n",
    "dataset = 'Proxifier'\n",
    "print(f'Processing {dataset} dataset...')\n",
    "# load the dataset\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "logs = df['Content'].tolist()\n",
    "templates = df['EventTemplate'].tolist()\n",
    "\n",
    "# tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "tokenized_logs = [tokenize(log) for log in logs]\n",
    "labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 11\n",
      "len of templates: 8\n",
      "cluster: 10\n",
      "length: 31\n",
      "template: <*> open through proxy <*> SOCKS5\n",
      "--------------------\n",
      "16.client-channel.google.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "13.client-channel.google.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "www.google.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "183.62.156.108:22 open through proxy socks.cse.cuhk.edu.hk:5070 SOCKS5\n",
      "bolt.dropbox.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "config.pinyin.sogou.com:80 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy closed the connection unexpectedly.\n",
      "qa.sockets.stackexchange.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "client-cf.dropbox.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "tcpconn4.tencent.com:80 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy closed the connection unexpectedly.\n",
      "mtalk.google.com:5228 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "86.99.222.235:443 error : Could not connect through proxy proxy.cse.cuhk.edu.hk:5070 - Proxy closed the connection unexpectedly.\n",
      "client-lb.dropbox.com:443 error : Could not connect to proxy proxy.cse.cuhk.edu.hk:5070 - connection attempt failed with error 10061\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "num = 10\n",
    "print('cluster:', num)\n",
    "print('length:', len(inputs[num][1]))\n",
    "print('template:', inputs[num][3])\n",
    "print('-'*20)\n",
    "for log in set(inputs[num][1]):\n",
    "    print(log)\n",
    "print('='*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the cluster k\n",
    "# k = 0\n",
    "# lengh_cluster = len(inputs[k][1])\n",
    "# print('cluster ', k)\n",
    "# print('length:', lengh_cluster)\n",
    "# print('template:', inputs[k][3])\n",
    "# print('-'*20)\n",
    "# for log in set(inputs[k][1]):\n",
    "#     print(log)\n",
    "\n",
    "#      len\n",
    "# Linux 0.5   tokenize '=' difference between (<*>) and () group first will help\n",
    "# HealthApp: 1   same length, 2 words different(80 logs) refine by difference of words will help\n",
    "# Zookeeper: 0 same length, 2 words different(12 logs)\n",
    "# Hadoop: 0 same length 1 words different(118 logs)\n",
    "# Spark: 0  same length 1 words different(149 logs)\n",
    "\n",
    "# good cluster datasets\n",
    "# HDFS OpenStack Proxifier HPC Mac Windows Apache Thunderbird\n",
    "# length solved datasets\n",
    "# BGL OpenSSH Android\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.852</td>\n",
       "      <td>7.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.666</td>\n",
       "      <td>1.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.638</td>\n",
       "      <td>3.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.691</td>\n",
       "      <td>3.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.574</td>\n",
       "      <td>14.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.765</td>\n",
       "      <td>6.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Proxifier</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>16.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.452</td>\n",
       "      <td>5.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.437</td>\n",
       "      <td>14.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.738</td>\n",
       "      <td>4.923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from utils.evaluator import evaluate\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def calculate_avg(numbers):\n",
    "    avg = sum(numbers) / len(numbers)\n",
    "    numbers.append(avg)\n",
    "    numbers = [round(num, 3) for num in numbers]\n",
    "    return numbers\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache Proxifier OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "\n",
    "table_data = {\n",
    "    'dataset': [],\n",
    "    'GA': [],\n",
    "    'PA': [],\n",
    "    'ED': []\n",
    "}\n",
    "\n",
    "# Note: chage the file name to the name of the log file\n",
    "file_name = '0shot_bestTry'\n",
    "\n",
    "result_table_path = f'outputs/parser/{file_name}/result_tabel.csv'\n",
    "if os.path.exists(result_table_path):\n",
    "    df = pd.read_csv(result_table_path)\n",
    "else:\n",
    "    ga, pa ,ed = [],[],[]\n",
    "    for dataset in datasets:\n",
    "        table_data['dataset'].append(dataset)\n",
    "        file_path = f'outputs/parser/{file_name}/{dataset}.csv'\n",
    "        \n",
    "        a,b,c,d = evaluate(file_path, dataset)\n",
    "        ga.append(a)\n",
    "        pa.append(b)\n",
    "        ed.append(c)\n",
    "\n",
    "    table_data['dataset'].append('avg')\n",
    "    table_data['GA'] = calculate_avg(ga)\n",
    "    table_data['PA'] = calculate_avg(pa)\n",
    "    table_data['ED'] = calculate_avg(ed)\n",
    "\n",
    "    df = pd.DataFrame(table_data)\n",
    "    df.to_csv(result_table_path, index=False)\n",
    "\n",
    "table = df.to_html(index=False)\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similarity in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count_logs = []\n",
    "count_templates = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            if any(char.isdigit() for char in template):\n",
    "                print(f\"{template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demonstrations_sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutation\n",
    "```\n",
    "# if '3' in template:\n",
    "#     Count[3] += 1\n",
    "# if '4' in template:\n",
    "#     Count[4] += 1\n",
    "#     # Mac 15 + 28 + 5 + 18 + 10\n",
    "# if '5' in template:\n",
    "#     Count[5] += 1\n",
    "#     print(dataset, template)\n",
    "#     # 1 + 2\n",
    "# if '6' in template:\n",
    "#     Count[6] += 1\n",
    "#     # Mac 15 + 28 + 5 + 18 + 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ddr errors(s) detected and corrected on rank 0, symbol 25, bit 1\n",
      "Can not get assembly information for node card\n",
      "ciod: Error loading /bgl/apps/scaletest/performance/MINIBEN/mb_243_0810/allreduce.rts: invalid or missing program image, Exec format error\n",
      "ciod: generated 64 core files for program IMB-MPI1.2MB_perf\n",
      "ciod: Error loading /bgl/apps/swl-prep/rky-swl/MPI-PERF/IMB/perf_tests/IMB-MPI1.5124KB: invalid or missing program image, No such file or directory\n",
      "1 ddr error(s) detected and corrected on rank 0, symbol 24 over 335 seconds\n",
      "minus normalized number..................0\n",
      "0MB HIGHMEM available.\n",
      "126MB LOWMEM available.\n",
      "Initializing random number generator:  succeeded\n",
      "Final resource view: name=cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us phys_ram=64172MB used_ram=2560MB phys_disk=15GB used_disk=20GB total_vcpus=16 used_vcpus=1 pci_stats=[]\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] Attempting claim: memory 2048 MB, disk 20 GB, vcpus 1 CPU\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] Total memory: 64172 MB, used: 512.00 MB\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] memory limit: 96258.00 MB, free: 95746.00 MB\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 2933 bytes (2.86 KB) sent, 11721005 bytes (11.1 MB) received, lifetime 02:48\n",
      "ecmb.bdimg.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
      "clusterAddMember  (command 1902)\n",
      "psu failure\\ ambient=28\n",
      "ambient=30\n",
      "network changed: v4(en0-:10.105.163.202) v6(en0:2607:f140:6000:8:c6b3:1ff:fecd:467f) DNS! Proxy SMB\n",
      "network changed: v4(en0:10.105.160.237) v6(en0!:2607:f140:6000:8:f1dc:a608:863:19ad) DNS Proxy SMB\n",
      "hibernate_machine_init pagesDone 455920 sum2 81cafc41, time: 185 ms, disk(0x20000) 847 Mb/s, comp bytes: 47288320 time: 32 ms 1369 Mb/s, crypt bytes: 158441472 time: 38 ms 3973 Mb/s\n",
      "network changed: v4(en0!:10.105.162.105) DNS+ Proxy+ SMB\n",
      "**** [BroadcomBluetoothHostControllerUSBTransport][start] -- Completed (matched on Device) -- 0x6000 ****\n",
      "hostControllerOnline - Number of Paired devices = 1, List of Paired devices = ( \"84-41-67-32-db-e1\" )\n",
      "**** [BroadcomBluetoothHostController][SetupController] -- Delay HCI Reset by 300ms  ****\n",
      "[QL] No sandbox token for request <QLThumbnailRequest vmware-usbarb-25037.log>, it will probably fail\n",
      "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10\n",
      "Number of reduces for job job_1445144423722_0020 = 1\n",
      "onInterceptTouchEvent MotionEvent { action=ACTION_DOWN, actionButton=0, id[0]=0, x[0]=317.0, y[0]=419.0, toolType[0]=TOOL_TYPE_FINGER, buttonState=0, metaState=0, flags=0x0, edgeFlags=0x0, pointerCount=1, historySize=0, eventTime=261851646, downTime=261851646, deviceId=3, source=0x1002 }, mBlockTouches=false\n",
      "onInterceptTouchEvent MotionEvent { action=ACTION_UP, actionButton=0, id[0]=0, x[0]=317.0, y[0]=419.0, toolType[0]=TOOL_TYPE_FINGER, buttonState=0, metaState=0, flags=0x0, edgeFlags=0x0, pointerCount=1, historySize=0, eventTime=261851713, downTime=261851646, deviceId=3, source=0x1002 }, mBlockTouches=false\n",
      "updateIsPoweredLocked: wasPowered=false, mIsPowered=false, oldPlugType=0, mPlugType=0, mBatteryLevel=23\n",
      "Read out cached package applicability for package: Microsoft-Windows-Embedded-EmbeddedLockdown-Package-TopLevel~31bf3856ad364e35~amd64~~7.1.7601.16511, ApplicableState: 112, CurrentState:0\n",
      "eth0: e1000_watchdog: NIC Link is Up 1000 Mbps Full Duplex\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import tokenize\n",
    "\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "a,b = 0,0\n",
    "pattern = r'^[a-zA-Z]+[0-9]+$'\n",
    "\n",
    "\n",
    "list_log = []\n",
    "list_tmp = []\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    logs = df['Content'].tolist()\n",
    "    freq = Counter(templates)\n",
    "    \n",
    "    for template,log in zip(templates,logs):\n",
    "        if 'mb' in log.lower() and template not in list_tmp:\n",
    "            list_tmp.append(template)\n",
    "            list_log.append(log)\n",
    "            \n",
    "for log in list_log:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
      "103.9375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "\n",
    "            'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# datasets = ['Linux']\n",
    "\n",
    "count_list = []\n",
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    with open (f'outputs/parser/Test/{dataset}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    Read = False\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if 'len=' in line and 'cluster' in line:\n",
    "            parts = line.strip().split(\"len=\")\n",
    "            if len(parts) == 2:  # 确保字符串中包含\"len=\"\n",
    "                tmp = parts[1]\n",
    "            else:\n",
    "                print(\"wrong\")\n",
    "                exit()\n",
    "            count += int(tmp)//50\n",
    "            count += 1 if int(tmp)%50 else 0\n",
    "    count_list.append(count)\n",
    "print(count_list)\n",
    "\n",
    "# [147, 49, 156, 98, 65, 202, 45, 61, 82, 361, 143, 164, 93, 43, 203, 69]\n",
    "# [137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
    "print(sum(count_list)/len(count_list))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "101 // 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
