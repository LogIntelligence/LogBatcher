{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Proxifier dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyi\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "# select the dataset\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# num_list = []\n",
    "# datasets = ['OpenStack']\n",
    "# for dataset in datasets:\n",
    "dataset = 'Proxifier'\n",
    "print(f'Processing {dataset} dataset...')\n",
    "# load the dataset\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "logs = df['Content'].tolist()\n",
    "templates = df['EventTemplate'].tolist()\n",
    "\n",
    "# tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "tokenized_logs = [tokenize(log) for log in logs]\n",
    "labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 14\n",
      "len of templates: 8\n",
      "cluster: 7\n",
      "length: 9\n",
      "template: <*> close, <*> sent, <*> received, lifetime <*>\n",
      "--------------------\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 31257 bytes (30.5 KB) sent, 1846301 bytes (1.76 MB) received, lifetime 01:33\n",
      "r6---sn-i3b7kn7d.googlevideo.com:443 close, 12789 bytes (12.4 KB) sent, 13833013 bytes (13.1 MB) received, lifetime 01:01\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 2933 bytes (2.86 KB) sent, 11721005 bytes (11.1 MB) received, lifetime 02:48\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 47856 bytes (46.7 KB) sent, 4090387 bytes (3.90 MB) received, lifetime 01:01\n",
      "video-hkg3-2.xx.fbcdn.net:443 close, 58373 bytes (57.0 KB) sent, 8896991 bytes (8.48 MB) received, lifetime 02:25\n",
      "r2---sn-i3b7kne6.googlevideo.com:443 close, 17742 bytes (17.3 KB) sent, 11581393 bytes (11.0 MB) received, lifetime 01:08\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 7437 bytes (7.26 KB) sent, 2235596 bytes (2.13 MB) received, lifetime 00:07\n",
      "r1---sn-i3belnez.googlevideo.com:443 close, 10046 bytes (9.81 KB) sent, 5657896 bytes (5.39 MB) received, lifetime 00:54\n",
      "r6---sn-i3b7knez.googlevideo.com:443 close, 13118 bytes (12.8 KB) sent, 3242984 bytes (3.09 MB) received, lifetime 00:31\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "num = 7\n",
    "print('cluster:', num)\n",
    "print('length:', len(inputs[num][1]))\n",
    "print('template:', inputs[num][3])\n",
    "print('-'*20)\n",
    "for log in set(inputs[num][1]):\n",
    "    print(log)\n",
    "print('='*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the cluster k\n",
    "# k = 0\n",
    "# lengh_cluster = len(inputs[k][1])\n",
    "# print('cluster ', k)\n",
    "# print('length:', lengh_cluster)\n",
    "# print('template:', inputs[k][3])\n",
    "# print('-'*20)\n",
    "# for log in set(inputs[k][1]):\n",
    "#     print(log)\n",
    "\n",
    "#      len\n",
    "# Linux 0.5   tokenize '=' difference between (<*>) and () group first will help\n",
    "# HealthApp: 1   same length, 2 words different(80 logs) refine by difference of words will help\n",
    "# Zookeeper: 0 same length, 2 words different(12 logs)\n",
    "# Hadoop: 0 same length 1 words different(118 logs)\n",
    "# Spark: 0  same length 1 words different(149 logs)\n",
    "\n",
    "# good cluster datasets\n",
    "# HDFS OpenStack Proxifier HPC Mac Windows Apache Thunderbird\n",
    "# length solved datasets\n",
    "# BGL OpenSSH Android\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.858</td>\n",
       "      <td>7.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.864</td>\n",
       "      <td>2.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.702</td>\n",
       "      <td>3.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.666</td>\n",
       "      <td>4.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.779</td>\n",
       "      <td>5.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Proxifier</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>25.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.440</td>\n",
       "      <td>14.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.806</td>\n",
       "      <td>4.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from utils.evaluator import evaluate\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def calculate_avg(numbers):\n",
    "    avg = sum(numbers) / len(numbers)\n",
    "    numbers.append(avg)\n",
    "    numbers = [round(num, 3) for num in numbers]\n",
    "    return numbers\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache Proxifier OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "\n",
    "table_data = {\n",
    "    'dataset': [],\n",
    "    'GA': [],\n",
    "    'PA': [],\n",
    "    'ED': []\n",
    "}\n",
    "\n",
    "# Note: chage the file name to the name of the log file\n",
    "file_name = 'Test'\n",
    "\n",
    "result_table_path = f'outputs/parser/{file_name}/result_tabel.csv'\n",
    "if os.path.exists(result_table_path):\n",
    "    df = pd.read_csv(result_table_path)\n",
    "else:\n",
    "    ga, pa ,ed = [],[],[]\n",
    "    for dataset in datasets:\n",
    "        table_data['dataset'].append(dataset)\n",
    "        file_path = f'outputs/parser/{file_name}/{dataset}.csv'\n",
    "        \n",
    "        a,b,c,d = evaluate(file_path, dataset)\n",
    "        ga.append(a)\n",
    "        pa.append(b)\n",
    "        ed.append(c)\n",
    "\n",
    "    table_data['dataset'].append('avg')\n",
    "    table_data['GA'] = calculate_avg(ga)\n",
    "    table_data['PA'] = calculate_avg(pa)\n",
    "    table_data['ED'] = calculate_avg(ed)\n",
    "\n",
    "    df = pd.DataFrame(table_data)\n",
    "    df.to_csv(result_table_path, index=False)\n",
    "\n",
    "table = df.to_html(index=False)\n",
    "display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similarity in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL ----------------\n",
      "ciod: Error loading <*>: invalid or missing program image, No such file or directory\n",
      "ciod: Error creating node map from file <*>: No child processes\n",
      "ciod: Error creating node map from file <*>: Bad file descriptor\n",
      "ciod: Error creating node map from file <*>: Block device required\n",
      "ciod: Error creating node map from file <*>: Permission denied\n",
      "rts: kernel terminated for reason <*>: bad message header: invalid cpu, type=<*>, cpu=<*>, index=<*>, total=<*>\n",
      "ciod: Error loading <*>: invalid or missing program image, Exec format error\n",
      "ciod: Error reading message prefix after LOAD_MESSAGE on CioStream socket to <*>: Link has been severed\n",
      "ciod: Error loading <*>: invalid or missing program image, Permission denied\n",
      "ciod: Error loading <*>: program image too big, <*> > <*>\n",
      "Processing HDFS ----------------\n",
      "<*>:Got exception while serving <*> to <*>:\n",
      "Processing Linux ----------------\n",
      "<*>: Auto-detected intellimouse <*>\n",
      "<*>: <*> - <*> (usable)\n",
      "<*>: <*> - <*> (reserved)\n",
      "PID hash table entries: <*> (order <*>: <*> bytes)\n",
      "<*>:  Registering secondary module capability\n",
      "<*>: PCI Hot Plug PCI Core version: <*>\n",
      "Processing HealthApp ----------------\n",
      "Processing OpenStack ----------------\n",
      "Processing OpenSSH ----------------\n",
      "Received disconnect from <*>: <*>: Bye Bye [preauth]\n",
      "error: Received disconnect from <*>: <*>: <*>: Auth fail [preauth]\n",
      "Received disconnect from <*>: <*>: Closed due to user request. [preauth]\n",
      "error: Received disconnect from <*>: <*>: No more user authentication methods available. [preauth]\n",
      "Received disconnect from <*>: <*>: disconnected by user\n",
      "Processing Proxifier ----------------\n",
      "Processing HPC ----------------\n",
      "Link error on broadcast tree Interconnect-<*>:<*>:<*>:<*>\n",
      "Processing Zookeeper ----------------\n",
      "Processing Mac ----------------\n",
      "ARPT: <*>: <*>::syncPowerState: WWEN[enabled]\n",
      "ARPT: <*>: <*>::platformWoWEnable: WWEN[disable]\n",
      "ARPT: <*>: IOPMPowerSource Information: onSleep, SleepType: Normal Sleep, 'ExternalConnected': Yes, 'TimeRemaining': <*>,\n",
      "ARPT: <*>: wl0: wl_update_tcpkeep_seq: Original Seq: <*>, Ack: <*>, Win size: <*>\n",
      "ARPT: <*>: ARPT: Wake Reason: Wake on Scan offload\n",
      "<*>::setAwdlAutoMode Resuming AWDL\n",
      "ARPT: <*>: wl0: MDNS: <*> SRV Recs, <*> TXT Recs\n",
      "com.apple.<*>: scheduler_evaluate_activity told me to run this job; however, but the start time isn't for <*> seconds. Ignoring.\n",
      "ARPT: <*>: wl0: Roamed or switched channel, reason #<*>, bssid <*>, last RSSI <*>\n",
      "<*>::setAwdlSuspendedMode() Suspending AWDL, enterQuietMode(<*>)\n",
      "ARPT: <*>: wl0: MDNS: IPV6 Addr: <*>\n",
      "ARPT: <*>: <*>::platformWoWEnable: WWEN[enable]\n",
      "<*>::<*> - retries = <*>\n",
      "ARPT: <*>: wl0: wl_update_tcpkeep_seq: Updated seq/ack/win from UserClient Seq <*>, Ack <*>, Win size <*>\n",
      "<*>::<*>::postMessage bssid changed\n",
      "<*>::<*> - intel_rp = <*> dlla_reporting_supported = <*>\n",
      "ARPT: <*>: wl0: setup_keepalive: Local port: <*>, Remote port: <*>\n",
      "ARPT: <*>: AQM agg results <*> len hi/lo: <*> BAbitmap(<*>) <*>\n",
      "<*>::setAwdlOperatingMode Setting the AWDL operation mode from AUTO to SUSPENDED\n",
      "ARPT: <*>: wl0: setup_keepalive: interval <*>, retry_interval <*>, retry_count <*>\n",
      "ARPT: <*>: wl0: MDNS: IPV4 Addr: <*>\n",
      "<*>::setAwdlOperatingMode Setting the AWDL operation mode from SUSPENDED to AUTO\n",
      "[<*>:WARNING:dns_config_service_posix.cc(<*>)] Failed to read DnsConfig.\n",
      "ARPT: <*>: wl0: setup_keepalive: Seq: <*>, Ack: <*>, Win size: <*>\n",
      "<*>::prePCIWake - power up complete - took <*> us\n",
      "<*> | I | VoipWrapper | DAVEngineImpl.cpp:<*>:Close | close video chat. llFriendUIN = <*>.\n",
      "ARPT: <*>: IOPMPowerSource Information: onSleep, SleepType: Normal Sleep, 'ExternalConnected': No, 'TimeRemaining': <*>,\n",
      "ARPT: <*>: wl0: setup_keepalive: Local IP: <*>\n",
      "Path not allowed in target domain: type = pid, path = <*> error = <*>: The specified service did not ship in the requestor's bundle, origin = <*>\n",
      "ARPT: <*>: wl0: leaveModulePoweredForOffloads: Wi-Fi will stay on.\n",
      "ARPT: <*>: IOPMPowerSource Information: onWake, SleepType: Normal Sleep, 'ExternalConnected': Yes, 'TimeRemaining': <*>,\n",
      "<*>: IPv6 address <*> has no prefix\n",
      "ARPT: <*>: AQM agg params <*> maxlen hi/lo <*> minlen <*> adjlen <*>\n",
      "ARPT: <*>: ARPT: Wake Reason: Wake on TCP Timeout\n",
      "ARPT: <*>: <*>::powerChange: System Wake - Full Wake/ Dark Wake / Maintenance wake\n",
      "ARPT: <*>: framerdy <*> bmccmd <*> framecnt <*>\n",
      "<IMMacNotificationCenterManager: <*>: DND Enabled: YES\n",
      "ARPT: <*>: wl0: setup_keepalive: Remote IP: <*>\n",
      "ARPT: <*>: wlc_dump_aggfifo:\n",
      "doSaveChannels@<*>: Will write to: <*>\n",
      "ARPT: <*>: IOPMPowerSource Information: onSleep, SleepType: Standby, 'ExternalConnected': No, 'TimeRemaining': <*>,\n",
      "ARPT: <*>: <*>::powerChange: System Sleep\n",
      "<IMMacNotificationCenterManager: <*>: Updating enabled: YES (Topics: (<*>))\n",
      "<IMMacNotificationCenterManager: <*>: notification observer: com.apple.FaceTime notification: __CFNotification <*> {name = _NSDoNotDisturbEnabledNotification}\n",
      "<IMMacNotificationCenterManager: <*>: NC Disabled: NO\n",
      "<IMMacNotificationCenterManager: <*>: DND Enabled: NO\n",
      "ARPT: <*>: IOPMPowerSource Information: onWake, SleepType: Normal Sleep, 'ExternalConnected': No, 'TimeRemaining': <*>,\n",
      "<IMMacNotificationCenterManager: <*>: Updating enabled: NO (Topics: ( ))\n",
      "Sandbox: <*>(<*>) deny(<*>) ipc-posix-shm-read-data CFPBS:<*>:\n",
      "Could not get event name for stream/token: com.apple.xpc.activity/<*>: <*>: Request for stale data\n",
      "<*> GoogleSoftwareUpdateAgent[<*>] [lvl=<*>] -[KSUpdateCheckAction performAction] KSUpdateCheckAction starting update check for ticket(s): {( <KSTicket:<*> productID=<*> version=<*> xc=<KSPathExistenceChecker:<*> path=<*> serverType=Omaha url=<*> creationDate=<*> tagPath=<*> tagKey=KSChannelID brandPath=<*> brandKey=KSBrandID versionPath=<*> versionKey=KSVersion cohort=<*>: cohortName=Stable ticketVersion=<*> > )} Using server: <KSOmahaServer:<*> engine=<KSUpdateEngine:<*> >\n",
      "<<<< MediaValidator >>>> <*>: Unrecognized codec <*>.(<*>). Failed codec specific check.\n",
      "<*> ERROR: <*>: timed out after <*> (<*>); mMajorChangePending=<*>\n",
      "Processing Hadoop ----------------\n",
      "IPC Server listener on <*>: starting\n",
      "getResources() for <*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>\n",
      "Diagnostics report from <*>: Container killed by the ApplicationMaster.\n",
      "Error Recovery for block BP-<*> in pipeline <*>, <*>: bad datanode <*>\n",
      "Diagnostics report from <*>: Error: java.net.NoRouteToHostException: No Route to Host from MININT-<*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost\n",
      "Processing Android ----------------\n",
      "remove(PendingIntent{<*>: PendingIntentRecord{<*> <*> broadcastIntent}}) changed bounds; rebatching\n",
      "<*>: <*> cannot be cast to <*>$Token\n",
      "<*>: Must execute in UI\n",
      "sending alarm Alarm{<*> type <*> when <*> PendingIntent{<*>: PendingIntentRecord{<*> android broadcastIntent}}},repeatInterval = <*>,listenerTag =time_tick\n",
      "sending alarm Alarm{<*> type <*> when <*> PendingIntent{<*>: PendingIntentRecord{<*> <*> broadcastIntent}}},repeatInterval = <*>,listenerTag =<*>\n",
      "Unable to start service Intent { act=<*> cmp=<*> } U=<*>: not found\n",
      "Process <*>:qzone (pid <*>) has died\n",
      "new Process app=ProcessRecord{<*> <*>}, name: <*>:qzone, euid: <*>\n",
      "Processing Windows ----------------\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> WcpInitialize (wcp.dll version <*>) called (stack @<*>)\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> CSI Transaction @<*> initialized for deployment engine {<*>} with flags <*> and client id [<*>]\"<*>/\"\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> CSI Transaction @<*> destroyed\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> PopulateComponentFamiliesKey - Begin\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> PopulateComponentFamiliesKey - End\n",
      "Processing Apache ----------------\n",
      "Processing Thunderbird ----------------\n",
      "<*>: from=<*>, size=<*>, class=<*>, nrcpts=<*>, msgid=<*>, relay=<*>@localhost\n",
      "<*>: to=<*>, ctladdr=<*> (0/0), delay=<*>, xdelay=<*>, mailer=relay, pri=<*>, relay=[<*>] [<*>], dsn=<*>, stat=Deferred: Connection refused by [<*>]\n",
      "<*>:USB HID core driver\n",
      "<*>: <*>: Intel(R) PRO/<*> Network Connection\n",
      "eth0: <*>: NIC Link is Up <*> Mbps Full Duplex\n",
      "probe new device <*>: bus <*>:slot <*>:func <*>\n",
      "Processing Spark ----------------\n",
      "<*>: Committed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count_logs = []\n",
    "count_templates = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            if '<*>:' in template:\n",
    "                print(f\"{template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demonstrations_sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutation\n",
    "```\n",
    "# if '3' in template:\n",
    "#     Count[3] += 1\n",
    "# if '4' in template:\n",
    "#     Count[4] += 1\n",
    "#     # Mac 15 + 28 + 5 + 18 + 10\n",
    "# if '5' in template:\n",
    "#     Count[5] += 1\n",
    "#     print(dataset, template)\n",
    "#     # 1 + 2\n",
    "# if '6' in template:\n",
    "#     Count[6] += 1\n",
    "#     # Mac 15 + 28 + 5 + 18 + 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ddr errors(s) detected and corrected on rank 0, symbol 25, bit 1\n",
      "Can not get assembly information for node card\n",
      "ciod: Error loading /bgl/apps/scaletest/performance/MINIBEN/mb_243_0810/allreduce.rts: invalid or missing program image, Exec format error\n",
      "ciod: generated 64 core files for program IMB-MPI1.2MB_perf\n",
      "ciod: Error loading /bgl/apps/swl-prep/rky-swl/MPI-PERF/IMB/perf_tests/IMB-MPI1.5124KB: invalid or missing program image, No such file or directory\n",
      "1 ddr error(s) detected and corrected on rank 0, symbol 24 over 335 seconds\n",
      "minus normalized number..................0\n",
      "0MB HIGHMEM available.\n",
      "126MB LOWMEM available.\n",
      "Initializing random number generator:  succeeded\n",
      "Final resource view: name=cp-1.slowvm1.tcloud-pg0.utah.cloudlab.us phys_ram=64172MB used_ram=2560MB phys_disk=15GB used_disk=20GB total_vcpus=16 used_vcpus=1 pci_stats=[]\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] Attempting claim: memory 2048 MB, disk 20 GB, vcpus 1 CPU\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] Total memory: 64172 MB, used: 512.00 MB\n",
      "[instance: 96abccce-8d1f-4e07-b6d1-4b2ab87e23b4] memory limit: 96258.00 MB, free: 95746.00 MB\n",
      "proxy.cse.cuhk.edu.hk:5070 close, 2933 bytes (2.86 KB) sent, 11721005 bytes (11.1 MB) received, lifetime 02:48\n",
      "ecmb.bdimg.com:80 open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
      "clusterAddMember  (command 1902)\n",
      "psu failure\\ ambient=28\n",
      "ambient=30\n",
      "network changed: v4(en0-:10.105.163.202) v6(en0:2607:f140:6000:8:c6b3:1ff:fecd:467f) DNS! Proxy SMB\n",
      "network changed: v4(en0:10.105.160.237) v6(en0!:2607:f140:6000:8:f1dc:a608:863:19ad) DNS Proxy SMB\n",
      "hibernate_machine_init pagesDone 455920 sum2 81cafc41, time: 185 ms, disk(0x20000) 847 Mb/s, comp bytes: 47288320 time: 32 ms 1369 Mb/s, crypt bytes: 158441472 time: 38 ms 3973 Mb/s\n",
      "network changed: v4(en0!:10.105.162.105) DNS+ Proxy+ SMB\n",
      "**** [BroadcomBluetoothHostControllerUSBTransport][start] -- Completed (matched on Device) -- 0x6000 ****\n",
      "hostControllerOnline - Number of Paired devices = 1, List of Paired devices = ( \"84-41-67-32-db-e1\" )\n",
      "**** [BroadcomBluetoothHostController][SetupController] -- Delay HCI Reset by 300ms  ****\n",
      "[QL] No sandbox token for request <QLThumbnailRequest vmware-usbarb-25037.log>, it will probably fail\n",
      "Input size for job job_1445144423722_0020 = 1256521728. Number of splits = 10\n",
      "Number of reduces for job job_1445144423722_0020 = 1\n",
      "onInterceptTouchEvent MotionEvent { action=ACTION_DOWN, actionButton=0, id[0]=0, x[0]=317.0, y[0]=419.0, toolType[0]=TOOL_TYPE_FINGER, buttonState=0, metaState=0, flags=0x0, edgeFlags=0x0, pointerCount=1, historySize=0, eventTime=261851646, downTime=261851646, deviceId=3, source=0x1002 }, mBlockTouches=false\n",
      "onInterceptTouchEvent MotionEvent { action=ACTION_UP, actionButton=0, id[0]=0, x[0]=317.0, y[0]=419.0, toolType[0]=TOOL_TYPE_FINGER, buttonState=0, metaState=0, flags=0x0, edgeFlags=0x0, pointerCount=1, historySize=0, eventTime=261851713, downTime=261851646, deviceId=3, source=0x1002 }, mBlockTouches=false\n",
      "updateIsPoweredLocked: wasPowered=false, mIsPowered=false, oldPlugType=0, mPlugType=0, mBatteryLevel=23\n",
      "Read out cached package applicability for package: Microsoft-Windows-Embedded-EmbeddedLockdown-Package-TopLevel~31bf3856ad364e35~amd64~~7.1.7601.16511, ApplicableState: 112, CurrentState:0\n",
      "eth0: e1000_watchdog: NIC Link is Up 1000 Mbps Full Duplex\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import tokenize\n",
    "\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "a,b = 0,0\n",
    "pattern = r'^[a-zA-Z]+[0-9]+$'\n",
    "\n",
    "\n",
    "list_log = []\n",
    "list_tmp = []\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    logs = df['Content'].tolist()\n",
    "    freq = Counter(templates)\n",
    "    \n",
    "    for template,log in zip(templates,logs):\n",
    "        if 'mb' in log.lower() and template not in list_tmp:\n",
    "            list_tmp.append(template)\n",
    "            list_log.append(log)\n",
    "            \n",
    "for log in list_log:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL dataset...\n",
      "60\n",
      "51\n",
      "Processing HDFS dataset...\n",
      "Processing Linux dataset...\n",
      "372\n",
      "216\n",
      "118\n",
      "Processing HealthApp dataset...\n",
      "242\n",
      "144\n",
      "Processing OpenStack dataset...\n",
      "931\n",
      "Processing OpenSSH dataset...\n",
      "384\n",
      "Processing Proxifier dataset...\n",
      "954\n",
      "947\n",
      "Processing HPC dataset...\n",
      "394\n",
      "91\n",
      "60\n",
      "Processing Zookeeper dataset...\n",
      "266\n",
      "Processing Mac dataset...\n",
      "Processing Hadoop dataset...\n",
      "476\n",
      "326\n",
      "Processing Android dataset...\n",
      "200\n",
      "Processing Windows dataset...\n",
      "280\n",
      "224\n",
      "224\n",
      "Processing Apache dataset...\n",
      "Processing Thunderbird dataset...\n",
      "568\n",
      "62\n",
      "Processing Spark dataset...\n",
      "80\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "\n",
    "            'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# datasets = ['Linux']\n",
    "\n",
    "count_list = []\n",
    "\n",
    "shot = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset...\")\n",
    "    with open (f'outputs/parser/Test/{dataset}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    Read = False\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if 'len=' in line and 'cluster' in line:\n",
    "            if count > 5:\n",
    "                print(length)\n",
    "                shot+=1\n",
    "            count = 0\n",
    "            parts = line.strip().split(\"len=\")\n",
    "            if len(parts) == 2:  # 确保字符串中包含\"len=\"\n",
    "                tmp = parts[1]\n",
    "                length = int(tmp)\n",
    "            if length > 50:\n",
    "                Read = True\n",
    "            else:\n",
    "                Read = False\n",
    "        else:\n",
    "            if Read:\n",
    "                count += 1\n",
    "\n",
    "print(shot/len(datasets))\n",
    "# [147, 49, 156, 98, 65, 202, 45, 61, 82, 361, 143, 164, 93, 43, 203, 69]\n",
    "# [137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "101 // 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
