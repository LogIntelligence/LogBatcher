{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Clustering Spark dataset...\n",
      "  (0, 20)\t0.3806911080032897\n",
      "  (0, 18)\t0.3806911080032897\n",
      "  (0, 41)\t0.3806911080032897\n",
      "  (0, 65)\t0.3806911080032897\n",
      "  (0, 68)\t0.3806911080032897\n",
      "  (0, 103)\t0.3806911080032897\n",
      "  (0, 29)\t0.3611726480831096\n",
      "  (1, 55)\t0.4114818567001452\n",
      "  (1, 123)\t0.4114818567001452\n",
      "  (1, 112)\t0.4114818567001452\n",
      "  (1, 42)\t0.3916802369701665\n",
      "  (1, 121)\t0.4114818567001452\n",
      "  (1, 8)\t0.4114818567001452\n",
      "  (2, 88)\t0.4114818567001452\n",
      "  (2, 55)\t0.4114818567001452\n",
      "  (2, 123)\t0.4114818567001452\n",
      "  (2, 112)\t0.4114818567001452\n",
      "  (2, 42)\t0.3916802369701665\n",
      "  (2, 8)\t0.4114818567001452\n",
      "  (3, 56)\t0.19245833180690344\n",
      "  (3, 57)\t0.19245833180690344\n",
      "  (3, 35)\t0.3849166636138069\n",
      "  (3, 94)\t0.3849166636138069\n",
      "  (3, 122)\t0.35870970679039343\n",
      "  (3, 117)\t0.3849166636138069\n",
      "  :\t:\n",
      "  (1994, 110)\t0.35165791637761523\n",
      "  (1995, 76)\t0.5773502691896258\n",
      "  (1995, 48)\t0.5773502691896258\n",
      "  (1995, 15)\t0.5773502691896258\n",
      "  (1996, 101)\t0.3602529779586415\n",
      "  (1996, 100)\t0.3602529779586415\n",
      "  (1996, 14)\t0.3602529779586415\n",
      "  (1996, 51)\t0.3208784221853493\n",
      "  (1996, 2)\t0.2731525333910825\n",
      "  (1996, 106)\t0.2731525333910825\n",
      "  (1996, 70)\t0.24578929328180898\n",
      "  (1996, 110)\t0.2183778051608804\n",
      "  (1996, 61)\t0.3598401412504461\n",
      "  (1996, 111)\t0.3476774813842624\n",
      "  (1997, 110)\t0.3958701246315886\n",
      "  (1997, 45)\t0.6493407597033204\n",
      "  (1997, 17)\t0.6493407597033204\n",
      "  (1998, 2)\t0.43986269884345497\n",
      "  (1998, 106)\t0.43986269884345497\n",
      "  (1998, 70)\t0.39579915495409984\n",
      "  (1998, 31)\t0.576820033562357\n",
      "  (1998, 110)\t0.35165791637761523\n",
      "  (1999, 76)\t0.5773502691896258\n",
      "  (1999, 48)\t0.5773502691896258\n",
      "  (1999, 15)\t0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "datasets = ['Spark']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('-' * 50)\n",
    "    print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "\n",
    "    # tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "    tokenized_logs = [tokenize(log) for log in logs]\n",
    "    print(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "    labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n",
    "\n",
    "    # store the logs in the cluster\n",
    "    # inputs = []\n",
    "    # for i in range(cluster_nums):\n",
    "    #     inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "    # for i, label in enumerate(labels):\n",
    "    #     inputs[label][0] = label\n",
    "    #     inputs[label][1].append(logs[i])\n",
    "    #     inputs[label][2].append(i)\n",
    "    #     if inputs[label][3] == '':\n",
    "    #         inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "    # clusters = []\n",
    "    # for input in inputs:\n",
    "    #     c = Cluster(*input, remove_duplicate= True)\n",
    "    #     clusters.append(c)\n",
    "    # Count = 0\n",
    "    # for c in clusters:    \n",
    "    #     if len(c.indexs) > 10:\n",
    "    #         print(c.logs[0])\n",
    "    #         print(c.oracle_template)\n",
    "    #         print(len(c.indexs))\n",
    "    #         print('=' * 50)\n",
    "    #         Count+=1\n",
    "    # print(f'Count : {Count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 38\n",
      "len of templates: 36\n",
      "cluster: 1\n",
      "length: 305\n",
      "template: Running task <*> in stage <*> (TID <*>)\n",
      "len of set: 305\n",
      "--------------------\n",
      "Running task 26.0 in stage 26.0 (TID 1226)\n",
      "Running task 0.0 in stage 20.0 (TID 807)\n",
      "Running task 32.0 in stage 27.0 (TID 1272)\n",
      "Running task 0.0 in stage 5.0 (TID 206)\n",
      "Running task 26.0 in stage 28.0 (TID 1306)\n",
      "Running task 2.0 in stage 17.0 (TID 716)\n",
      "Running task 1.0 in stage 29.0 (TID 1321)\n",
      "Running task 8.0 in stage 26.0 (TID 1208)\n",
      "Running task 32.0 in stage 26.0 (TID 1232)\n",
      "Running task 1.0 in stage 19.0 (TID 776)\n",
      "Running task 1.0 in stage 6.0 (TID 261)\n",
      "Running task 5.0 in stage 27.0 (TID 1245)\n",
      "Running task 12.0 in stage 27.0 (TID 1252)\n",
      "Running task 1.0 in stage 22.0 (TID 900)\n",
      "Running task 4.0 in stage 13.0 (TID 559)\n",
      "Running task 15.0 in stage 29.0 (TID 1335)\n",
      "Running task 4.0 in stage 20.0 (TID 839)\n",
      "Running task 2.0 in stage 21.0 (TID 877)\n",
      "Running task 33.0 in stage 26.0 (TID 1233)\n",
      "Running task 41.0 in stage 24.0 (TID 1126)\n",
      "Running task 5.0 in stage 29.0 (TID 1325)\n",
      "Running task 4.0 in stage 24.0 (TID 1026)\n",
      "Running task 1.0 in stage 0.0 (TID 1)\n",
      "Running task 34.0 in stage 26.0 (TID 1234)\n",
      "Running task 2.0 in stage 29.0 (TID 1322)\n",
      "Running task 3.0 in stage 11.0 (TID 478)\n",
      "Running task 35.0 in stage 26.0 (TID 1235)\n",
      "Running task 2.0 in stage 28.0 (TID 1282)\n",
      "Running task 1.0 in stage 23.0 (TID 940)\n",
      "Running task 4.0 in stage 0.0 (TID 4)\n",
      "Running task 1.0 in stage 15.0 (TID 626)\n",
      "Running task 37.0 in stage 27.0 (TID 1277)\n",
      "Running task 29.0 in stage 27.0 (TID 1269)\n",
      "Running task 0.0 in stage 28.0 (TID 1280)\n",
      "Running task 84.0 in stage 24.0 (TID 1141)\n",
      "Running task 3.0 in stage 3.0 (TID 158)\n",
      "Running task 2.0 in stage 10.0 (TID 430)\n",
      "Running task 1.0 in stage 12.0 (TID 494)\n",
      "Running task 1.0 in stage 24.0 (TID 984)\n",
      "Running task 4.0 in stage 26.0 (TID 1204)\n",
      "Running task 21.0 in stage 28.0 (TID 1301)\n",
      "Running task 28.0 in stage 28.0 (TID 1308)\n",
      "Running task 82.0 in stage 24.0 (TID 1137)\n",
      "Running task 3.0 in stage 22.0 (TID 918)\n",
      "Running task 42.0 in stage 24.0 (TID 1127)\n",
      "Running task 7.0 in stage 26.0 (TID 1207)\n",
      "Running task 1.0 in stage 25.0 (TID 1180)\n",
      "Running task 29.0 in stage 26.0 (TID 1229)\n",
      "Running task 34.0 in stage 29.0 (TID 1354)\n",
      "Running task 4.0 in stage 4.0 (TID 199)\n",
      "Running task 1.0 in stage 21.0 (TID 867)\n",
      "Running task 22.0 in stage 26.0 (TID 1222)\n",
      "Running task 4.0 in stage 27.0 (TID 1244)\n",
      "Running task 1.0 in stage 3.0 (TID 136)\n",
      "Running task 121.0 in stage 24.0 (TID 1146)\n",
      "Running task 0.0 in stage 27.0 (TID 1240)\n",
      "Running task 21.0 in stage 27.0 (TID 1261)\n",
      "Running task 124.0 in stage 24.0 (TID 1151)\n",
      "Running task 3.0 in stage 28.0 (TID 1283)\n",
      "Running task 11.0 in stage 28.0 (TID 1291)\n",
      "Running task 0.0 in stage 0.0 (TID 0)\n",
      "Running task 15.0 in stage 28.0 (TID 1295)\n",
      "Running task 29.0 in stage 29.0 (TID 1349)\n",
      "Running task 4.0 in stage 15.0 (TID 639)\n",
      "Running task 6.0 in stage 27.0 (TID 1246)\n",
      "Running task 3.0 in stage 24.0 (TID 1012)\n",
      "Running task 19.0 in stage 29.0 (TID 1339)\n",
      "Running task 9.0 in stage 29.0 (TID 1329)\n",
      "Running task 2.0 in stage 0.0 (TID 2)\n",
      "Running task 2.0 in stage 16.0 (TID 671)\n",
      "Running task 3.0 in stage 23.0 (TID 958)\n",
      "Running task 4.0 in stage 19.0 (TID 799)\n",
      "Running task 2.0 in stage 22.0 (TID 912)\n",
      "Running task 7.0 in stage 28.0 (TID 1287)\n",
      "Running task 31.0 in stage 28.0 (TID 1311)\n",
      "Running task 17.0 in stage 29.0 (TID 1337)\n",
      "Running task 18.0 in stage 28.0 (TID 1298)\n",
      "Running task 43.0 in stage 24.0 (TID 1128)\n",
      "Running task 4.0 in stage 2.0 (TID 119)\n",
      "Running task 2.0 in stage 7.0 (TID 312)\n",
      "Running task 17.0 in stage 27.0 (TID 1257)\n",
      "Running task 13.0 in stage 27.0 (TID 1253)\n",
      "Running task 0.0 in stage 10.0 (TID 402)\n",
      "Running task 2.0 in stage 15.0 (TID 636)\n",
      "Running task 14.0 in stage 29.0 (TID 1334)\n",
      "Running task 1.0 in stage 1.0 (TID 56)\n",
      "Running task 12.0 in stage 29.0 (TID 1332)\n",
      "Running task 11.0 in stage 26.0 (TID 1211)\n",
      "Running task 9.0 in stage 28.0 (TID 1289)\n",
      "Running task 21.0 in stage 26.0 (TID 1221)\n",
      "Running task 163.0 in stage 24.0 (TID 1158)\n",
      "Running task 18.0 in stage 27.0 (TID 1258)\n",
      "Running task 1.0 in stage 13.0 (TID 542)\n",
      "Running task 17.0 in stage 26.0 (TID 1217)\n",
      "Running task 39.0 in stage 26.0 (TID 1239)\n",
      "Running task 1.0 in stage 4.0 (TID 185)\n",
      "Running task 120.0 in stage 24.0 (TID 1145)\n",
      "Running task 36.0 in stage 26.0 (TID 1236)\n",
      "Running task 34.0 in stage 28.0 (TID 1314)\n",
      "Running task 0.0 in stage 15.0 (TID 612)\n",
      "Running task 24.0 in stage 27.0 (TID 1264)\n",
      "Running task 0.0 in stage 21.0 (TID 853)\n",
      "Running task 0.0 in stage 24.0 (TID 970)\n",
      "Running task 2.0 in stage 23.0 (TID 951)\n",
      "Running task 4.0 in stage 11.0 (TID 479)\n",
      "Running task 3.0 in stage 15.0 (TID 638)\n",
      "Running task 8.0 in stage 28.0 (TID 1288)\n",
      "Running task 162.0 in stage 24.0 (TID 1157)\n",
      "Running task 0.0 in stage 16.0 (TID 643)\n",
      "Running task 26.0 in stage 27.0 (TID 1266)\n",
      "Running task 1.0 in stage 18.0 (TID 736)\n",
      "Running task 25.0 in stage 26.0 (TID 1225)\n",
      "Running task 3.0 in stage 17.0 (TID 718)\n",
      "Running task 1.0 in stage 26.0 (TID 1201)\n",
      "Running task 12.0 in stage 28.0 (TID 1292)\n",
      "Running task 36.0 in stage 27.0 (TID 1276)\n",
      "Running task 2.0 in stage 24.0 (TID 998)\n",
      "Running task 7.0 in stage 29.0 (TID 1327)\n",
      "Running task 19.0 in stage 28.0 (TID 1299)\n",
      "Running task 8.0 in stage 29.0 (TID 1328)\n",
      "Running task 3.0 in stage 18.0 (TID 758)\n",
      "Running task 0.0 in stage 17.0 (TID 692)\n",
      "Running task 0.0 in stage 9.0 (TID 360)\n",
      "Running task 1.0 in stage 11.0 (TID 464)\n",
      "Running task 11.0 in stage 29.0 (TID 1331)\n",
      "Running task 0.0 in stage 23.0 (TID 926)\n",
      "Running task 20.0 in stage 28.0 (TID 1300)\n",
      "Running task 160.0 in stage 24.0 (TID 1155)\n",
      "Running task 38.0 in stage 27.0 (TID 1278)\n",
      "Running task 3.0 in stage 12.0 (TID 518)\n",
      "Running task 16.0 in stage 27.0 (TID 1256)\n",
      "Running task 23.0 in stage 27.0 (TID 1263)\n",
      "Running task 3.0 in stage 13.0 (TID 558)\n",
      "Running task 122.0 in stage 24.0 (TID 1147)\n",
      "Running task 38.0 in stage 26.0 (TID 1238)\n",
      "Running task 22.0 in stage 27.0 (TID 1262)\n",
      "Running task 39.0 in stage 27.0 (TID 1279)\n",
      "Running task 2.0 in stage 25.0 (TID 1194)\n",
      "Running task 6.0 in stage 29.0 (TID 1326)\n",
      "Running task 4.0 in stage 1.0 (TID 79)\n",
      "Running task 14.0 in stage 28.0 (TID 1294)\n",
      "Running task 3.0 in stage 4.0 (TID 198)\n",
      "Running task 0.0 in stage 1.0 (TID 42)\n",
      "Running task 0.0 in stage 8.0 (TID 321)\n",
      "Running task 15.0 in stage 26.0 (TID 1215)\n",
      "Running task 1.0 in stage 20.0 (TID 821)\n",
      "Running task 161.0 in stage 24.0 (TID 1156)\n",
      "Running task 27.0 in stage 26.0 (TID 1227)\n",
      "Running task 25.0 in stage 29.0 (TID 1345)\n",
      "Running task 20.0 in stage 26.0 (TID 1220)\n",
      "Running task 4.0 in stage 17.0 (TID 719)\n",
      "Running task 13.0 in stage 26.0 (TID 1213)\n",
      "Running task 1.0 in stage 10.0 (TID 416)\n",
      "Running task 3.0 in stage 10.0 (TID 438)\n",
      "Running task 0.0 in stage 26.0 (TID 1200)\n",
      "Running task 24.0 in stage 26.0 (TID 1224)\n",
      "Running task 2.0 in stage 6.0 (TID 273)\n",
      "Running task 2.0 in stage 14.0 (TID 590)\n",
      "Running task 10.0 in stage 26.0 (TID 1210)\n",
      "Running task 39.0 in stage 28.0 (TID 1319)\n",
      "Running task 31.0 in stage 29.0 (TID 1351)\n",
      "Running task 3.0 in stage 25.0 (TID 1198)\n",
      "Running task 16.0 in stage 28.0 (TID 1296)\n",
      "Running task 9.0 in stage 27.0 (TID 1249)\n",
      "Running task 16.0 in stage 29.0 (TID 1336)\n",
      "Running task 3.0 in stage 6.0 (TID 278)\n",
      "Running task 23.0 in stage 26.0 (TID 1223)\n",
      "Running task 1.0 in stage 17.0 (TID 706)\n",
      "Running task 28.0 in stage 26.0 (TID 1228)\n",
      "Running task 19.0 in stage 27.0 (TID 1259)\n",
      "Running task 25.0 in stage 27.0 (TID 1265)\n",
      "Running task 34.0 in stage 27.0 (TID 1274)\n",
      "Running task 0.0 in stage 2.0 (TID 87)\n",
      "Running task 17.0 in stage 28.0 (TID 1297)\n",
      "Running task 4.0 in stage 16.0 (TID 679)\n",
      "Running task 2.0 in stage 18.0 (TID 750)\n",
      "Running task 4.0 in stage 10.0 (TID 439)\n",
      "Running task 4.0 in stage 29.0 (TID 1324)\n",
      "Running task 0.0 in stage 3.0 (TID 122)\n",
      "Running task 14.0 in stage 27.0 (TID 1254)\n",
      "Running task 2.0 in stage 2.0 (TID 112)\n",
      "Running task 4.0 in stage 23.0 (TID 959)\n",
      "Running task 15.0 in stage 27.0 (TID 1255)\n",
      "Running task 33.0 in stage 27.0 (TID 1273)\n",
      "Running task 3.0 in stage 16.0 (TID 678)\n",
      "Running task 80.0 in stage 24.0 (TID 1135)\n",
      "Running task 1.0 in stage 27.0 (TID 1241)\n",
      "Running task 27.0 in stage 28.0 (TID 1307)\n",
      "Running task 4.0 in stage 5.0 (TID 239)\n",
      "Running task 31.0 in stage 27.0 (TID 1271)\n",
      "Running task 30.0 in stage 28.0 (TID 1310)\n",
      "Running task 2.0 in stage 27.0 (TID 1242)\n",
      "Running task 10.0 in stage 29.0 (TID 1330)\n",
      "Running task 19.0 in stage 26.0 (TID 1219)\n",
      "Running task 20.0 in stage 29.0 (TID 1340)\n",
      "Running task 13.0 in stage 29.0 (TID 1333)\n",
      "Running task 2.0 in stage 8.0 (TID 349)\n",
      "Running task 2.0 in stage 19.0 (TID 789)\n",
      "Running task 37.0 in stage 28.0 (TID 1317)\n",
      "Running task 13.0 in stage 28.0 (TID 1293)\n",
      "Running task 3.0 in stage 19.0 (TID 798)\n",
      "Running task 37.0 in stage 26.0 (TID 1237)\n",
      "Running task 30.0 in stage 29.0 (TID 1350)\n",
      "Running task 44.0 in stage 24.0 (TID 1129)\n",
      "Running task 83.0 in stage 24.0 (TID 1138)\n",
      "Running task 4.0 in stage 22.0 (TID 919)\n",
      "Running task 81.0 in stage 24.0 (TID 1136)\n",
      "Running task 5.0 in stage 26.0 (TID 1205)\n",
      "Running task 3.0 in stage 27.0 (TID 1243)\n",
      "Running task 164.0 in stage 24.0 (TID 1159)\n",
      "Running task 28.0 in stage 27.0 (TID 1268)\n",
      "Running task 0.0 in stage 25.0 (TID 1166)\n",
      "Running task 6.0 in stage 28.0 (TID 1286)\n",
      "Running task 3.0 in stage 9.0 (TID 398)\n",
      "Running task 1.0 in stage 16.0 (TID 657)\n",
      "Running task 0.0 in stage 18.0 (TID 722)\n",
      "Running task 8.0 in stage 27.0 (TID 1248)\n",
      "Running task 0.0 in stage 22.0 (TID 886)\n",
      "Running task 4.0 in stage 6.0 (TID 279)\n",
      "Running task 2.0 in stage 3.0 (TID 150)\n",
      "Running task 4.0 in stage 14.0 (TID 599)\n",
      "Running task 18.0 in stage 26.0 (TID 1218)\n",
      "Running task 7.0 in stage 27.0 (TID 1247)\n",
      "Running task 10.0 in stage 28.0 (TID 1290)\n",
      "Running task 21.0 in stage 29.0 (TID 1341)\n",
      "Running task 0.0 in stage 6.0 (TID 247)\n",
      "Running task 32.0 in stage 28.0 (TID 1312)\n",
      "Running task 1.0 in stage 2.0 (TID 101)\n",
      "Running task 24.0 in stage 29.0 (TID 1344)\n",
      "Running task 3.0 in stage 8.0 (TID 358)\n",
      "Running task 4.0 in stage 3.0 (TID 159)\n",
      "Running task 16.0 in stage 26.0 (TID 1216)\n",
      "Running task 1.0 in stage 14.0 (TID 576)\n",
      "Running task 3.0 in stage 2.0 (TID 118)\n",
      "Running task 3.0 in stage 26.0 (TID 1203)\n",
      "Running task 30.0 in stage 26.0 (TID 1230)\n",
      "Running task 30.0 in stage 27.0 (TID 1270)\n",
      "Running task 28.0 in stage 29.0 (TID 1348)\n",
      "Running task 35.0 in stage 27.0 (TID 1275)\n",
      "Running task 3.0 in stage 20.0 (TID 838)\n",
      "Running task 10.0 in stage 27.0 (TID 1250)\n",
      "Running task 33.0 in stage 28.0 (TID 1313)\n",
      "Running task 2.0 in stage 26.0 (TID 1202)\n",
      "Running task 2.0 in stage 11.0 (TID 475)\n",
      "Running task 0.0 in stage 14.0 (TID 562)\n",
      "Running task 4.0 in stage 7.0 (TID 319)\n",
      "Running task 18.0 in stage 29.0 (TID 1338)\n",
      "Running task 3.0 in stage 7.0 (TID 318)\n",
      "Running task 1.0 in stage 28.0 (TID 1281)\n",
      "Running task 26.0 in stage 29.0 (TID 1346)\n",
      "Running task 2.0 in stage 13.0 (TID 553)\n",
      "Running task 3.0 in stage 1.0 (TID 78)\n",
      "Running task 14.0 in stage 26.0 (TID 1214)\n",
      "Running task 32.0 in stage 29.0 (TID 1352)\n",
      "Running task 4.0 in stage 28.0 (TID 1284)\n",
      "Running task 4.0 in stage 8.0 (TID 359)\n",
      "Running task 4.0 in stage 18.0 (TID 759)\n",
      "Running task 4.0 in stage 21.0 (TID 879)\n",
      "Running task 6.0 in stage 26.0 (TID 1206)\n",
      "Running task 31.0 in stage 26.0 (TID 1231)\n",
      "Running task 0.0 in stage 29.0 (TID 1320)\n",
      "Running task 3.0 in stage 5.0 (TID 238)\n",
      "Running task 3.0 in stage 14.0 (TID 598)\n",
      "Running task 2.0 in stage 20.0 (TID 833)\n",
      "Running task 11.0 in stage 27.0 (TID 1251)\n",
      "Running task 3.0 in stage 29.0 (TID 1323)\n",
      "Running task 2.0 in stage 9.0 (TID 388)\n",
      "Running task 2.0 in stage 5.0 (TID 231)\n",
      "Running task 3.0 in stage 21.0 (TID 878)\n",
      "Running task 0.0 in stage 11.0 (TID 450)\n",
      "Running task 0.0 in stage 12.0 (TID 480)\n",
      "Running task 40.0 in stage 24.0 (TID 1125)\n",
      "Running task 12.0 in stage 26.0 (TID 1212)\n",
      "Running task 24.0 in stage 28.0 (TID 1304)\n",
      "Running task 1.0 in stage 5.0 (TID 220)\n",
      "Running task 2.0 in stage 12.0 (TID 508)\n",
      "Running task 33.0 in stage 29.0 (TID 1353)\n",
      "Running task 22.0 in stage 28.0 (TID 1302)\n",
      "Running task 2.0 in stage 4.0 (TID 195)\n",
      "Running task 38.0 in stage 28.0 (TID 1318)\n",
      "Running task 3.0 in stage 0.0 (TID 3)\n",
      "Running task 9.0 in stage 26.0 (TID 1209)\n",
      "Running task 22.0 in stage 29.0 (TID 1342)\n",
      "Running task 0.0 in stage 7.0 (TID 285)\n",
      "Running task 4.0 in stage 12.0 (TID 519)\n",
      "Running task 25.0 in stage 28.0 (TID 1305)\n",
      "Running task 0.0 in stage 4.0 (TID 171)\n",
      "Running task 0.0 in stage 19.0 (TID 762)\n",
      "Running task 29.0 in stage 28.0 (TID 1309)\n",
      "Running task 1.0 in stage 7.0 (TID 299)\n",
      "Running task 27.0 in stage 27.0 (TID 1267)\n",
      "Running task 27.0 in stage 29.0 (TID 1347)\n",
      "Running task 36.0 in stage 28.0 (TID 1316)\n",
      "Running task 23.0 in stage 28.0 (TID 1303)\n",
      "Running task 1.0 in stage 9.0 (TID 374)\n",
      "Running task 123.0 in stage 24.0 (TID 1150)\n",
      "Running task 1.0 in stage 8.0 (TID 335)\n",
      "Running task 5.0 in stage 28.0 (TID 1285)\n",
      "Running task 4.0 in stage 25.0 (TID 1199)\n",
      "Running task 20.0 in stage 27.0 (TID 1260)\n",
      "Running task 23.0 in stage 29.0 (TID 1343)\n",
      "Running task 35.0 in stage 28.0 (TID 1315)\n",
      "Running task 4.0 in stage 9.0 (TID 399)\n",
      "Running task 0.0 in stage 13.0 (TID 528)\n",
      "Running task 2.0 in stage 1.0 (TID 69)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "clusters = []\n",
    "for input in inputs:\n",
    "    c = Cluster(*input, remove_duplicate= True)\n",
    "    clusters.append(c)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     print(f'cluster {cluster.label}: {len(cluster.logs)} logs, {len(cluster.indexs)} indexs')\n",
    "\n",
    "num = 1\n",
    "print('cluster:', num)\n",
    "print('length:', len(clusters[num].indexs))\n",
    "print('template:', clusters[num].oracle_template)\n",
    "set_logs = set(clusters[num].static_logs)\n",
    "print('len of set:', len(set_logs))\n",
    "print('-'*20)\n",
    "for log in set_logs:\n",
    "    print(log)\n",
    "print('='*40)\n",
    "\n",
    "# for cluster in clusters:\n",
    "#     if len(set(cluster.logs)) == 1 and not any(char.isdigit() for char in cluster.logs[0]):\n",
    "#         print(f\"{cluster.logs[0]}\\n{cluster.oracle_template}\")\n",
    "#         print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000, Normalized Edit Distance: 1.000000\n",
      "      Hadoop: group Accuracy: 0.9885, Message-Level Accuracy: 0.8860, Edit Distance: 6.5805, Normalized Edit Distance: 0.951995\n",
      "       Spark: group Accuracy: 0.9975, Message-Level Accuracy: 0.9705, Edit Distance: 0.3705, Normalized Edit Distance: 0.988876\n",
      "   Zookeeper: group Accuracy: 0.9945, Message-Level Accuracy: 0.9875, Edit Distance: 0.4305, Normalized Edit Distance: 0.994671\n",
      "         BGL: group Accuracy: 0.9910, Message-Level Accuracy: 0.9435, Edit Distance: 1.8715, Normalized Edit Distance: 0.987947\n",
      "         HPC: group Accuracy: 0.9525, Message-Level Accuracy: 0.9440, Edit Distance: 0.3455, Normalized Edit Distance: 0.995789\n",
      " Thunderbird: group Accuracy: 0.9140, Message-Level Accuracy: 0.8555, Edit Distance: 2.3220, Normalized Edit Distance: 0.951463\n",
      "     Windows: group Accuracy: 1.0000, Message-Level Accuracy: 0.6085, Edit Distance: 12.0170, Normalized Edit Distance: 0.795275\n",
      "       Linux: group Accuracy: 0.9950, Message-Level Accuracy: 0.7285, Edit Distance: 2.3725, Normalized Edit Distance: 0.968886\n",
      "     Android: group Accuracy: 0.9550, Message-Level Accuracy: 0.8030, Edit Distance: 4.2105, Normalized Edit Distance: 0.958126\n",
      "   HealthApp: group Accuracy: 0.9145, Message-Level Accuracy: 0.9090, Edit Distance: 2.7810, Normalized Edit Distance: 0.958347\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 0.9780, Edit Distance: 0.2300, Normalized Edit Distance: 0.996156\n",
      "     OpenSSH: group Accuracy: 1.0000, Message-Level Accuracy: 0.9755, Edit Distance: 1.0385, Normalized Edit Distance: 0.989285\n",
      "   OpenStack: group Accuracy: 1.0000, Message-Level Accuracy: 0.9605, Edit Distance: 1.1325, Normalized Edit Distance: 0.988813\n",
      "         Mac: group Accuracy: 0.8295, Message-Level Accuracy: 0.5355, Edit Distance: 10.7015, Normalized Edit Distance: 0.878861\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "      <th>N_ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>6.5805</td>\n",
       "      <td>0.95199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>0.98888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.99467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.9435</td>\n",
       "      <td>1.8715</td>\n",
       "      <td>0.98795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.99579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>2.3220</td>\n",
       "      <td>0.95146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6085</td>\n",
       "      <td>12.0170</td>\n",
       "      <td>0.79528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>2.3725</td>\n",
       "      <td>0.96889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>0.95813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>2.7810</td>\n",
       "      <td>0.95835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.99616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>1.0385</td>\n",
       "      <td>0.98929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>1.1325</td>\n",
       "      <td>0.98881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>10.7015</td>\n",
       "      <td>0.87886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>3.0936</td>\n",
       "      <td>0.96030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'LogBatcher_0shot_32candidate_10batchsize_with_2', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BGL: group Accuracy: 0.7360, Message-Level Accuracy: 0.9495, Edit Distance: 1.0310, Normalized Edit Distance: 0.990357\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "# datasets = ['BGL', 'HDFS', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper']\n",
    "datasets = ['BGL']\n",
    "for dataset in datasets:\n",
    "    evaluate_single_dataset(\n",
    "        f'outputs/parser/Divlog_0shot_32candidate/{dataset}_2k.log_structured.csv', dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "count = 0\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates:\n",
    "            count_templates.append(template)\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Caclulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_prompt_tokens(prompt, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 计算编码后的token数\n",
    "    prompt_tokens = encoder.encode(prompt)\n",
    "    return len(prompt_tokens)\n",
    "\n",
    "\n",
    "def count_message_tokens(messages, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 初始化token计数\n",
    "    token_count = 0\n",
    "\n",
    "    # 计算每个消息的token数\n",
    "    for message in messages:\n",
    "        role_tokens = encoder.encode(message['role'])\n",
    "        content_tokens = encoder.encode(message['content'])\n",
    "        token_count += len(role_tokens) + \\\n",
    "            len(content_tokens) + 4  # 加上特殊的消息分隔符的token数\n",
    "\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs[dataset] = df['Content'].tolist()\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "for log in logs['HealthApp']:\n",
    "    log = log.strip()\n",
    "\n",
    "# 存储解析后的日志列表\n",
    "message_list = []\n",
    "# load every message\n",
    "file = 'cost_lilac_32_3.json'\n",
    "with open('outputs/cost/LogBatcher_3shot_32candidate_10batchsize.json', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == '[':\n",
    "            list_str = ''\n",
    "            start_load = True\n",
    "        if line.strip() == ']':\n",
    "            list_str += line\n",
    "            message = json.loads(list_str)\n",
    "            message_list.append(message)\n",
    "            start_load = False\n",
    "        if start_load:\n",
    "            list_str += line\n",
    "# print(len(message_list))\n",
    "for message in message_list:\n",
    "    # for LILAC\n",
    "    log = message[-1]['content'].split('\\n')[0].replace('Log message: `', '').replace('`', '')\n",
    "    # for LogBatcher\n",
    "    # log = message[-1]['content'].split('\\n')[0] \n",
    "    # print(log)\n",
    "    for dataset in datasets:\n",
    "        if log in logs[dataset]:\n",
    "            counts_token[dataset] += count_message_tokens(message, 'gpt-3.5-turbo')\n",
    "            counts_message[dataset] += 1\n",
    "            break\n",
    "        if dataset == 'Mac':\n",
    "            print(log)\n",
    "for dataset in datasets:\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset]  )\n",
    "\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))\n",
    "\n",
    "# remove the same log messages\n",
    "\n",
    "# def make_hashable(log_list):\n",
    "\n",
    "#     return tuple(tuple(sorted(d.items())) for d in log_list)\n",
    "# unique_lists = list(set(make_hashable(log_list) for log_list in message_list))\n",
    "\n",
    "# unique_big_list = [list(map(dict, log_list)) for log_list in unique_lists]\n",
    "# print(len(unique_big_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "# datasets = ['HDFS']\n",
    "logs = {}\n",
    "counts_token = {}\n",
    "counts_message = {}\n",
    "for dataset in datasets:\n",
    "    counts_token[dataset] = 0\n",
    "    counts_message[dataset] = 0\n",
    "    with open(f'DivLog/cost/cost_divlog_for_{dataset}.json', 'r') as file:\n",
    "        prompt_list = json.load(file)\n",
    "    # print(f\"caculate {dataset}: len: {len(prompt_list)}\")\n",
    "    for prompt in prompt_list:\n",
    "        counts_token[dataset] += count_prompt_tokens(prompt, 'gpt-3.5-turbo')\n",
    "        counts_message[dataset] += 1\n",
    "    print(counts_token[dataset], counts_token[dataset] / counts_message[dataset])\n",
    "\n",
    "# print average token count\n",
    "print(sum(counts_token.values()), sum(counts_token.values()) / sum(counts_message.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_prompt_tokens('For each log after <prompt> tag, extract one log template(substitute variable tokens in the log as <*> and remain constant tokens to construct the template)and put the template after <extraction> tag and between <START> and <END> tags.', 'gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sample_byword import extract_variables\n",
    "print(extract_variables(\"488205 floating point alignment exceptions\",\n",
    "      \"<*> floating point alignment exceptions\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
