{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Mac dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoyi\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "import time\n",
    "\n",
    "# select the dataset\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# num_list = []\n",
    "# datasets = ['OpenStack']\n",
    "# for dataset in datasets:\n",
    "dataset = 'Mac'\n",
    "print(f'Processing {dataset} dataset...')\n",
    "# load the dataset\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "logs = df['Content'].tolist()\n",
    "# logs.extend(df['Content'].tolist())\n",
    "templates = df['EventTemplate'].tolist()\n",
    "\n",
    "# tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "tokenized_logs = [tokenize(log) for log in logs]\n",
    "labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 366\n",
      "len of templates: 341\n",
      "cluster: 122\n",
      "length: 3\n",
      "template: [HID] [MT] AppleMultitouchDevice::willTerminate entered\n",
      "--------------------\n",
      "[HID] [MT] AppleMultitouchDevice::willTerminate entered\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "num = 122\n",
    "print('cluster:', num)\n",
    "print('length:', len(inputs[num][1]))\n",
    "print('template:', inputs[num][3])\n",
    "print('-'*20)\n",
    "for log in set(inputs[num][1]):\n",
    "    print(log)\n",
    "print('='*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000\n",
      "      Hadoop: group Accuracy: 0.9850, Message-Level Accuracy: 0.4495, Edit Distance: 12.2160\n",
      "       Spark: group Accuracy: 0.9220, Message-Level Accuracy: 0.8820, Edit Distance: 2.3325\n",
      "   Zookeeper: group Accuracy: 0.9915, Message-Level Accuracy: 0.9655, Edit Distance: 0.4070\n",
      "         BGL: group Accuracy: 0.9790, Message-Level Accuracy: 0.9560, Edit Distance: 0.9920\n",
      "         HPC: group Accuracy: 0.8760, Message-Level Accuracy: 0.8630, Edit Distance: 1.6555\n",
      " Thunderbird: group Accuracy: 0.9700, Message-Level Accuracy: 0.6235, Edit Distance: 4.7990\n",
      "     Windows: group Accuracy: 0.9960, Message-Level Accuracy: 0.9735, Edit Distance: 0.8555\n",
      "       Linux: group Accuracy: 0.4770, Message-Level Accuracy: 0.5990, Edit Distance: 3.3590\n",
      "     Android: group Accuracy: 0.9365, Message-Level Accuracy: 0.6465, Edit Distance: 5.8900\n",
      "   HealthApp: group Accuracy: 0.8715, Message-Level Accuracy: 0.7395, Edit Distance: 10.0250\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 0.9780, Edit Distance: 0.2300\n",
      "   Proxifier: group Accuracy: 0.5265, Message-Level Accuracy: 0.0165, Edit Distance: 21.6645\n",
      "     OpenSSH: group Accuracy: 0.9985, Message-Level Accuracy: 0.9975, Edit Distance: 0.1065\n",
      "   OpenStack: group Accuracy: 0.9895, Message-Level Accuracy: 0.9820, Edit Distance: 0.4110\n",
      "         Mac: group Accuracy: 0.8040, Message-Level Accuracy: 0.4400, Edit Distance: 14.6825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.450</td>\n",
       "      <td>12.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.882</td>\n",
       "      <td>2.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.863</td>\n",
       "      <td>1.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.624</td>\n",
       "      <td>4.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.599</td>\n",
       "      <td>3.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.646</td>\n",
       "      <td>5.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.740</td>\n",
       "      <td>10.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Proxifier</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.016</td>\n",
       "      <td>21.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.440</td>\n",
       "      <td>14.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.757</td>\n",
       "      <td>4.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets('Test3_0125_pure', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL ----------------\n",
      "Processing HDFS ----------------\n",
      "Processing Linux ----------------\n",
      "PCI: Using IRQ router PIIX/ICH [<*>/<*>] at <*>\n",
      "Processing HealthApp ----------------\n",
      "Processing OpenStack ----------------\n",
      "Processing OpenSSH ----------------\n",
      "Processing Proxifier ----------------\n",
      "Processing HPC ----------------\n",
      "Processing Zookeeper ----------------\n",
      "My election bind port: <*>/<*>\n",
      "Processing Mac ----------------\n",
      "-[UABestAppSuggestionManager notifyBestAppChanged:type:options:bundleIdentifier:activityType:dynamicIdentifier:when:confidence:deviceName:deviceIdentifier:deviceType:] (<*>) UASuggestedActionType=<*> (<*>)/(<*>) opts=(<*>) when=<*>\n",
      "after trim url = https://www.google.com/_/chrome/newtab?rlz=<*>&espv=<*>&ie=UTF-<*>\n",
      "Could not get event name for stream/token: com.apple.xpc.activity/<*>: <*>: Request for stale data\n",
      "Processing Hadoop ----------------\n",
      "Processing Android ----------------\n",
      "printFreezingDisplayLogsopening app wtoken = AppWindowToken{<*> token=Token{<*> ActivityRecord{<*> u0 <*>/.<*> t761}}}, allDrawn= <*>, startingDisplayed = <*>, startingMoved = <*>, isRelaunching = <*>\n",
      "Processing Windows ----------------\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> WcpInitialize (wcp.dll version <*>) called (stack @<*>)\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> CSI Transaction @<*> initialized for deployment engine {<*>} with flags <*> and client id [<*>]\"<*>/\"\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> CSI Transaction @<*> destroyed\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> PopulateComponentFamiliesKey - Begin\n",
      "<*>@<*>/<*>/<*>:<*>:<*>:<*> PopulateComponentFamiliesKey - End\n",
      "Processing Apache ----------------\n",
      "Processing Thunderbird ----------------\n",
      "<*>=LABEL=/ initrd=<*> console=<*> console=<*>,<*> fastboot BOOT_IMAGE=<*>\n",
      "<*>: <*>: Intel(R) PRO/<*> Network Connection\n",
      "PS/<*> mouse device common for all mice\n",
      "Processing Spark ----------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    for log, template in zip(logs, templates):\n",
    "        for token in template.split():\n",
    "            if '/' in token and '<*>' in token and template not in count_templates:\n",
    "                print(template)\n",
    "                count_templates.append(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demonstrations_sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Count -- num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4: 15 + 28 + 5 + 18 + 10\n",
    "# 5: 1 + 2\n",
    "# 6: 15 + 28 + 5 + 18 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import tokenize\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "a,b = 0,0\n",
    "pattern = r'^[a-zA-Z]+[0-9]+$'\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    list_log = []\n",
    "    list_tmp = []\n",
    "    print('-'*20)\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    logs = df['Content'].tolist()\n",
    "    freq = Counter(templates)\n",
    "    \n",
    "    for template,log in zip(templates,logs):\n",
    "        tokens = template.split()\n",
    "        for token in tokens:\n",
    "            if ':' in token and '<*>' in token:\n",
    "                # print(f\"{template}\\n{log}\\n{'-'*20}\")\n",
    "                list_tmp.append(template)\n",
    "                list_log.append(log)\n",
    "                break\n",
    "            \n",
    "    for tmp in list_tmp:\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "\n",
    "            'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "# datasets = ['Linux']\n",
    "\n",
    "count_list = []\n",
    "shot = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset...\")\n",
    "    with open (f'outputs/parser/Test/{dataset}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    Read = False\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if 'len=' in line and 'cluster' in line:\n",
    "            if count > 5:\n",
    "                print(length)\n",
    "                for tmp in tmp_list:\n",
    "                    print(tmp.strip('\\n'))\n",
    "                shot+=1\n",
    "            count = 0\n",
    "            tmp_list = []\n",
    "            parts = line.strip().split(\"len=\")\n",
    "            if len(parts) == 2:  # 确保字符串中包含\"len=\"\n",
    "                tmp = parts[1]\n",
    "                length = int(tmp)\n",
    "            if length > 50:\n",
    "                Read = True\n",
    "            else:\n",
    "                Read = False\n",
    "        else:\n",
    "            if Read:\n",
    "                tmp_list.append(line)\n",
    "                # print(line)\n",
    "                count += 1\n",
    "\n",
    "print(shot/len(datasets))\n",
    "# [147, 49, 156, 98, 65, 202, 45, 61, 82, 361, 143, 164, 93, 43, 203, 69]\n",
    "# [137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from utils.sample_byword import extract_variables\n",
    "\n",
    "matches = extract_variables(\n",
    "    '1 is over than 2 as result', '<*> is over than <*> as result')\n",
    "if matches == []:\n",
    "    print('no matches')\n",
    "if matches == ():\n",
    "    print(\"2\")\n",
    "else:\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<*> is <*>, logname=\n"
     ]
    }
   ],
   "source": [
    "template = '<*> is <*>, logname=<*>'\n",
    "list2 = ['1', '2', '']\n",
    "list1 = template.split('<*>')\n",
    "template2 = list1[0]\n",
    "for index, tmp in enumerate(list2):\n",
    "    if tmp != '':\n",
    "        template2 += '<*>' + list1[index + 1]\n",
    "    else:\n",
    "        template2 += list1[index + 1]\n",
    "print(template2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{{1}} is over {{2}}, logname = {{3}}', '<*> is over <*>, logname = ')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.postprocess import post_process\n",
    "\n",
    "post_process('`{{1}} is over {{2}}, logname = {{3}}`', '1 is over 2, logname = ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
