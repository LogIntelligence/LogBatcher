{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBCSAN Clustering\n",
    "`另一种聚类方式：将所有数字替换为0，不经过分词直接聚类`\n",
    "``` python\n",
    "re.sub(r'\\d+(\\.\\d+)?', '0', text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing with tokens\n",
      "Clustering hadoop dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import reassign_clusters, cluster, vectorize, tokenize,Cluster\n",
    "import time\n",
    "\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "dataset = 'hadoop'\n",
    "print(f'Clustering {dataset} dataset...')\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "logs = df['Content'].tolist()\n",
    "templates = df['EventTemplate'].tolist()\n",
    "\n",
    "# tokenize -> vectorize -> cluster -> reassign_clusters\n",
    "tokenized_logs = [tokenize(log) for log in logs]\n",
    "labels, cluster_nums = cluster(vectorize(tokenized_logs))\n",
    "labels, cluster_nums = reassign_clusters(labels, cluster_nums, tokenized_logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of clusters: 116\n",
      "len of templates: 114\n",
      "cluster: 23\n",
      "length: 289\n",
      "template: Progress of TaskAttempt <*> is : <*>\n",
      "len of set: 112\n",
      "--------------------\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.32285523\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.29998285\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.1066108\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.22765201\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.6199081\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.023958297\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.26314905\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.079464614\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.36323506\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.5091932\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.44968578\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.13841225\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.29597813\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.18529637\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.6854124\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.43890014\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.5806522\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.3638923\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.9854844\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.20639901\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.23859076\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.83331466\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.27613032\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37551183\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.19716828\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.19255035\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.3787692\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.19247705\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.36319977\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.38007197\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.9543898\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.10635664\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.2783809\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.26542902\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.76133776\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.19258286\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37225527\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.103304505\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.1337379\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.4156165\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.10875365\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.7607953\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.27776006\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.20757815\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.10685723\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.27696857\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.29115766\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.2754006\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.10681946\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.4956123\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.17293417\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.106493875\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.25258622\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.05713628\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.358454\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.27772525\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.10660437\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.19084874\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.36388028\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.36390656\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.10680563\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.80356\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.10501281\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.17982168\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.27765483\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.1795899\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.44950968\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.19242907\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.1430594\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.14981231\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.10004553\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.19266446\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.36404583\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.3624012\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.27825075\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.19211523\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000005_0 is : 0.27813601\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.5323719\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.06741504\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.33995733\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.32958937\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.2898827\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 1.0\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.5343203\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.106964506\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.87672114\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.35880664\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.19158794\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.667\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000006_0 is : 0.44980705\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.9185183\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.19209063\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000000_0 is : 0.065791264\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.3512319\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.37322965\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.3673702\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.19212553\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.34610128\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.38137424\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.7198902\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.24035259\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.27811313\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000009_0 is : 0.295472\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.4486067\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000001_0 is : 0.31981927\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.25511068\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000007_0 is : 0.3707891\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.106881365\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000003_0 is : 0.667\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000008_0 is : 0.18216328\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000002_0 is : 0.36317363\n",
      "Progress of TaskAttempt attempt_1445144423722_0020_m_000004_0 is : 0.2781602\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print('num of clusters:', cluster_nums)\n",
    "print('len of templates:', len(set(templates)))\n",
    "\n",
    "# store the logs in the cluster\n",
    "inputs = []\n",
    "for i in range(cluster_nums):\n",
    "    inputs.append([-1, [], [], '']) # label, logs, indexs, ground_truth\n",
    "for i, label in enumerate(labels):\n",
    "    inputs[label][0] = label\n",
    "    inputs[label][1].append(logs[i])\n",
    "    inputs[label][2].append(i)\n",
    "    if inputs[label][3] == '':\n",
    "        inputs[label][3] = df['EventTemplate'][i]\n",
    "\n",
    "num = 23\n",
    "print('cluster:', num)\n",
    "print('length:', len(inputs[num][1]))\n",
    "print('template:', inputs[num][3])\n",
    "print('len of set:', len(set(inputs[num][1])))\n",
    "print('-'*20)\n",
    "for log in set(inputs[num][1]):\n",
    "    print(log)\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HDFS: group Accuracy: 1.0000, Message-Level Accuracy: 0.9425, Edit Distance: 0.0575\n",
      "      Hadoop: group Accuracy: 0.9575, Message-Level Accuracy: 0.8430, Edit Distance: 3.0310\n",
      "       Spark: group Accuracy: 0.9980, Message-Level Accuracy: 0.8055, Edit Distance: 0.4050\n",
      "   Zookeeper: group Accuracy: 0.9885, Message-Level Accuracy: 0.3740, Edit Distance: 3.3065\n",
      "         BGL: group Accuracy: 0.9410, Message-Level Accuracy: 0.8695, Edit Distance: 3.7345\n",
      "         HPC: group Accuracy: 0.9110, Message-Level Accuracy: 0.6405, Edit Distance: 2.8530\n",
      " Thunderbird: group Accuracy: 0.9565, Message-Level Accuracy: 0.8515, Edit Distance: 2.2670\n",
      "     Windows: group Accuracy: 0.6940, Message-Level Accuracy: 0.0200, Edit Distance: 17.5835\n",
      "       Linux: group Accuracy: 0.2975, Message-Level Accuracy: 0.3435, Edit Distance: 5.1890\n",
      "     Android: group Accuracy: 0.9310, Message-Level Accuracy: 0.4805, Edit Distance: 10.8390\n",
      "   HealthApp: group Accuracy: 0.9005, Message-Level Accuracy: 0.7450, Edit Distance: 6.3495\n",
      "      Apache: group Accuracy: 1.0000, Message-Level Accuracy: 1.0000, Edit Distance: 0.0000\n",
      "     OpenSSH: group Accuracy: 0.7295, Message-Level Accuracy: 0.5120, Edit Distance: 4.4225\n",
      "   OpenStack: group Accuracy: 0.4915, Message-Level Accuracy: 0.4385, Edit Distance: 4.8885\n",
      "         Mac: group Accuracy: 0.7170, Message-Level Accuracy: 0.3995, Edit Distance: 17.3655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>GA</th>\n",
       "      <th>PA</th>\n",
       "      <th>ED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>HDFS</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Hadoop</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.843</td>\n",
       "      <td>3.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Spark</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Zookeeper</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.374</td>\n",
       "      <td>3.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BGL</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.870</td>\n",
       "      <td>3.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HPC</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.640</td>\n",
       "      <td>2.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thunderbird</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.852</td>\n",
       "      <td>2.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Windows</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.020</td>\n",
       "      <td>17.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linux</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.344</td>\n",
       "      <td>5.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Android</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.480</td>\n",
       "      <td>10.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HealthApp</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.745</td>\n",
       "      <td>6.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apache</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenSSH</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.512</td>\n",
       "      <td>4.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OpenStack</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.438</td>\n",
       "      <td>4.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mac</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.400</td>\n",
       "      <td>17.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avg</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.618</td>\n",
       "      <td>5.486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import evaluate_all_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "table = evaluate_all_datasets(\n",
    "    'result_LILAC_2k_0_0_gpt-3.5-turbo-0613', send_email=False)\n",
    "HTML(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hadoop: group Accuracy: 0.9890, Message-Level Accuracy: 0.6344, Edit Distance: 11.4817\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_single_dataset\n",
    "\n",
    "evaluate_single_dataset('outputs/parser/Test3/Hadoop.csv', 'Hadoop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0x1a3', '0X4D2', '0xABCDEF']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\b0[xX][0-9a-fA-F]+\\b'\n",
    "text = \"Here are some hex numbers: 0x1a3, 0X4D2, and 0xABCDEF.\"\n",
    "\n",
    "matches = re.findall(pattern, text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out some strings' freq in the whole logs or templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BGL ----------------\n",
      "Processing HDFS ----------------\n",
      "Processing Linux ----------------\n",
      "authentication failure; logname= uid=<*> euid=<*> tty=<*> ruser= rhost=<*>  user=<*>\n",
      "authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root\n",
      "--------------------\n",
      "ANONYMOUS FTP LOGIN FROM <*>,  (anonymous)\n",
      "ANONYMOUS FTP LOGIN FROM 84.102.20.2,  (anonymous)\n",
      "--------------------\n",
      "SELinux:  Initializing.\n",
      "SELinux:  Initializing.\n",
      "--------------------\n",
      "SELinux:  Starting in permissive mode\n",
      "SELinux:  Starting in permissive mode\n",
      "--------------------\n",
      "<*>:  Registering secondary module capability\n",
      "selinux_register_security:  Registering secondary module capability\n",
      "--------------------\n",
      "Initializing random number generator:  succeeded\n",
      "Initializing random number generator:  succeeded\n",
      "--------------------\n",
      "Starting pcmcia:  succeeded\n",
      "Starting pcmcia:  succeeded\n",
      "--------------------\n",
      "Setting network parameters:  succeeded\n",
      "Setting network parameters:  succeeded\n",
      "--------------------\n",
      "Bringing up loopback interface:  succeeded\n",
      "Bringing up loopback interface:  succeeded\n",
      "--------------------\n",
      "SELinux:  Registering netfilter hooks\n",
      "SELinux:  Registering netfilter hooks\n",
      "--------------------\n",
      "Processing HealthApp ----------------\n",
      "Processing OpenStack ----------------\n",
      "Processing OpenSSH ----------------\n",
      "Processing Proxifier ----------------\n",
      "Processing HPC ----------------\n",
      "Processing Zookeeper ----------------\n",
      "Processing Mac ----------------\n",
      "Processing Hadoop ----------------\n",
      "Processing Android ----------------\n",
      "Processing Windows ----------------\n",
      "Processing Apache ----------------\n",
      "Processing Thunderbird ----------------\n",
      "Processing Spark ----------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.cluster import tokenize\n",
    "from utils.sample_byword import extract_variables\n",
    "from utils.postprocess import correct_single_template\n",
    "from utils.postprocess import extract_variables\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "\n",
    "count_templates = []\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    logs = df['Content'].tolist()\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    # templates = list(set(templates))\n",
    "    for log, template in zip(logs, templates):\n",
    "        if template not in count_templates and '  ' in template:\n",
    "            count_templates.append(template)\n",
    "            print(template)\n",
    "            print(log)\n",
    "            print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample based on entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.demonstrations_sample import sample_based_on_entropy\n",
    "\n",
    "# datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "#         'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "# for dataset in datasets:\n",
    "#     pair = sample_based_on_entropy(dataset, 1)\n",
    "#     print(pair[0][0])\n",
    "dataset = 'HDFS'\n",
    "pairs = sample_based_on_entropy(dataset, 1)\n",
    "for pair in pairs:\n",
    "    print(f\"{pair[0][0]}\\n{pair[0][1]}\\n{'-'*20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation Count -- num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4: 15 + 28 + 5 + 18 + 10\n",
    "# 5: 1 + 2\n",
    "# 6: 15 + 28 + 5 + 18 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils.cluster import tokenize\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "a,b = 0,0\n",
    "pattern = r'^[a-zA-Z]+[0-9]+$'\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} ----------------\")\n",
    "    list_log = []\n",
    "    list_tmp = []\n",
    "    print('-'*20)\n",
    "    df = pd.read_csv(f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    logs = df['Content'].tolist()\n",
    "    freq = Counter(templates)\n",
    "    \n",
    "    for template,log in zip(templates,logs):\n",
    "        tokens = template.split()\n",
    "        for token in tokens:\n",
    "            if ':' in token and '<*>' in token:\n",
    "                # print(f\"{template}\\n{log}\\n{'-'*20}\")\n",
    "                list_tmp.append(template)\n",
    "                list_log.append(log)\n",
    "                break\n",
    "            \n",
    "    for tmp in list_tmp:\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC',\n",
    "\n",
    "            'Zookeeper', 'Mac', 'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "\n",
    "# datasets = ['Linux']\n",
    "\n",
    "count_list = []\n",
    "shot = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing {dataset} dataset...\")\n",
    "    with open (f'outputs/parser/Test/{dataset}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    Read = False\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if 'len=' in line and 'cluster' in line:\n",
    "            if count > 5:\n",
    "                print(length)\n",
    "                for tmp in tmp_list:\n",
    "                    print(tmp.strip('\\n'))\n",
    "                shot+=1\n",
    "            count = 0\n",
    "            tmp_list = []\n",
    "            parts = line.strip().split(\"len=\")\n",
    "            if len(parts) == 2:  # 确保字符串中包含\"len=\"\n",
    "                tmp = parts[1]\n",
    "                length = int(tmp)\n",
    "            if length > 50:\n",
    "                Read = True\n",
    "            else:\n",
    "                Read = False\n",
    "        else:\n",
    "            if Read:\n",
    "                tmp_list.append(line)\n",
    "                # print(line)\n",
    "                count += 1\n",
    "\n",
    "print(shot/len(datasets))\n",
    "# [147, 49, 156, 98, 65, 202, 45, 61, 82, 361, 143, 164, 93, 43, 203, 69]\n",
    "# [137, 49, 121, 94, 62, 56, 45, 56, 78, 322, 135, 141, 86, 43, 175, 63]\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no matches\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from utils.sample_byword import extract_variables\n",
    "\n",
    "matches = extract_variables(\n",
    "    '1 is over than 2 as result', '<*> is over than <*> as result')\n",
    "if matches == []:\n",
    "    print('no matches')\n",
    "if matches == ():\n",
    "    print(\"2\")\n",
    "else:\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<*> is <*>, logname=\n"
     ]
    }
   ],
   "source": [
    "template = '<*> is <*>, logname=<*>'\n",
    "list2 = ['1', '2', '']\n",
    "list1 = template.split('<*>')\n",
    "template2 = list1[0]\n",
    "for index, tmp in enumerate(list2):\n",
    "    if tmp != '':\n",
    "        template2 += '<*>' + list1[index + 1]\n",
    "    else:\n",
    "        template2 += list1[index + 1]\n",
    "print(template2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{{1}} is over {{2}}, logname = {{3}}', '<*> is over <*>, logname = ')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.postprocess import post_process\n",
    "\n",
    "post_process('`{{1}} is over {{2}}, logname = {{3}}`', '1 is over 2, logname = ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
