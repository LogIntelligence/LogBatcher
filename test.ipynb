{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openai 1.3.2 api 调用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import httpx\n",
    "\n",
    "api_key = \"sk-MWCZbiYqiQUjacuGF53a6c71E3134177A585CeFe79D10aD2\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://oneapi.xty.app/v1\",  # 中转url\n",
    "    api_key=api_key,                      # api_key\n",
    "    http_client=httpx.Client(\n",
    "        proxies=\"http://127.0.0.1:7890\"  # 代理地址\n",
    "    ),\n",
    ")\n",
    "\n",
    "with open(\"dataset\\Android\\Android_2k.log\", \"r\") as file:\n",
    "    log_messages = file.readlines()[:10]\n",
    "\n",
    "\n",
    "for log_message in log_messages:\n",
    "    prompt = \"repeat \" + log_message\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\":prompt}],\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用panda读取csv文件和log文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = 'Spark'\n",
    "\n",
    "with open('dataset\\\\' + dataset +\n",
    "          '\\\\' + dataset + '_2k.log', 'r') as logfile:\n",
    "    lines = logfile.readlines()\n",
    "\n",
    "# print len(log_messages)\n",
    "print(lines.__len__())\n",
    "\n",
    "print(lines[0])\n",
    "\n",
    "log_templates = pd.read_csv('dataset\\\\' + dataset + '\\\\' +\n",
    "                            dataset + '_2k.log_structured_corrected.csv')['EventTemplate']\n",
    "\n",
    "print(len(log_templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\\n这是一\\n个字符串\\n\"\n",
    "s = s.strip('\\n')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Stages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import httpx\n",
    "\n",
    "api_key = \"sk-MWCZbiYqiQUjacuGF53a6c71E3134177A585CeFe79D10aD2\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://oneapi.xty.app/v1\",  # 中转url\n",
    "    api_key=api_key,                      # api_key\n",
    "    http_client=httpx.Client(\n",
    "        proxies=\"http://127.0.0.1:7890\"  # 代理地址\n",
    "    ),\n",
    ")\n",
    "\n",
    "logs = ['17/06/09 20:10:48 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 21 ms',\n",
    "        '17/06/09 20:10:48 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 384.0 B, free 317.5 KB)',\n",
    "        '17/06/09 20:10:48 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4']\n",
    "\n",
    "codes = ['''logger.info(\"Reading broadcast variable {} took {} ms\", 0, 21)''',\n",
    "         '''logger.info(\"Block {} stored as values in memory (estimated size {} B, free {})\", \"broadcast_0\", 384.0, 317.5)\"''',\n",
    "         '''logger.info(\"Started reading broadcast variable {}\", 4)'''\n",
    "         ]\n",
    "\n",
    "instruction = '''Given the following raw log, firstly you should generate the corresponding logging statement (The logging statement is a single line of code that is used to log a message), then you should generate the log template by identifying the variable parts and replacing them with placeholders in the form of <*>, return the code and log template without additional explainations:'''\n",
    "\n",
    "demonstrations = [\n",
    "    {\"role\": \"user\", \"content\": logs[1]},\n",
    "    {   \n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": 'Logging statement: logger.info(\"Block {} stored as values in memory (estimated size {}, free {})\", \"broadcast_0\", \"384.0 B\", \"317.5 KB\")\\nLog template: Block <*> stored as bytes in memory (estimated size <*>, free <*>)'\n",
    "    },\n",
    "]\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": instruction})\n",
    "messages.append(demonstrations[0])\n",
    "messages.append(demonstrations[1])\n",
    "messages.append({\"role\": \"user\", \"content\": '17/06/09 20:10:48 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 95.0 B, free 317.6 KB)'})\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2 = response.choices[0].message.content.split('\\n')\n",
    "print(l1.replace('Logging statement: ',''))\n",
    "print(l2.replace('Log template: ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import reverse\n",
    "# choose dataset\n",
    "datasets = ['BGL', 'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac',\n",
    "            'Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "dataset = datasets[11]\n",
    "\n",
    "reverse('Android', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [1, 2, 3, 4, 5]\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i, q in enumerate(tqdm(list)):\n",
    "    time.sleep(1)\n",
    "    print(str(i) +':'+ str(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrations = {\n",
    "    'Spark': [{\"role\": \"user\", \"content\": 'Log: 17/06/09 20:10:48 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 384.0 B, free 317.5 KB)'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"Block {} stored as values in memory (estimated size {}, free {})\", \"broadcast_0\", \"384.0 B\", \"317.5 KB\")'}],\n",
    "    'Hadoop': [{\"role\": \"user\", \"content\": 'Log: 2015-10-18 18:01:53,885 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"{} TaskAttempt Transitioned from NEW to UNASSIGNED\", \"attempt_1445144423722_0020_m_000000_0\")'}],\n",
    "    'Linux': [{\"role\": \"user\", \"content\": 'Log: Jun 15 20:05:31 combo sshd(pam_unix)[24141]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=d211-116-254-214.rev.krline.net'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"authentication failure; logname= uid={} euid={} tty={} ruser= rhost={}\", \"0\", \"0\", \"NODEVssh\", \"d211-116-254-214.rev.krline.net\")'}],\n",
    "}\n",
    "\n",
    "print(demonstrations['Spark'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging statement: logger.info(\"authentication failure; logname= uid={} euid={} tty={} ruser= rhost={} user={}\", \"0\", \"0\", \"NODEVssh\", \"220-135-151-1.hinet-ip.hinet.net\", \"root\")\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import httpx\n",
    "import pandas as pd\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "api_key = \"sk-MWCZbiYqiQUjacuGF53a6c71E3134177A585CeFe79D10aD2\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://oneapi.xty.app/v1\",  # 中转url\n",
    "    api_key=api_key,                      # api_key\n",
    "    # http_client=httpx.Client(\n",
    "    #     proxies=\"http://127.0.0.1:7890\"  # 代理地址\n",
    "    # ),\n",
    ")\n",
    "\n",
    "dataset = 'Linux'\n",
    "\n",
    "# @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5))\n",
    "def get_responce(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip('\\n')\n",
    "\n",
    "\n",
    "instruction = '''Given the following raw log, you should generate the corresponding logging statement. The logging statement is a single line of code that is used to log a message. You need to understand the information in the raw log, determine the log level, extract all possible variables and replace them with placeholders, and finally generate the logging statement using the correct logging function and the log message with placeholders. All extracted variables should be passed as arguments to the logging function.'''\n",
    "\n",
    "demonstrations = {\n",
    "    'Spark': [{\"role\": \"user\", \"content\": 'Log: 17/06/09 20:10:48 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 384.0 B, free 317.5 KB)'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"Block {} stored as values in memory (estimated size {}, free {})\", \"broadcast_0\", \"384.0 B\", \"317.5 KB\")'}],\n",
    "    'Hadoop': [{\"role\": \"user\", \"content\": 'Log: 2015-10-18 18:01:53,885 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1445144423722_0020_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"{} TaskAttempt Transitioned from NEW to UNASSIGNED\", \"attempt_1445144423722_0020_m_000000_0\")'}],\n",
    "    'Linux': [{\"role\": \"user\", \"content\": 'Log: Jun 15 20:05:31 combo sshd(pam_unix)[24141]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=d211-116-254-214.rev.krline.net'}, {\"role\": \"assistant\", \"content\": 'Logging statement: logger.info(\"authentication failure; logname= uid={} euid={} tty={} ruser= rhost={}\", \"0\", \"0\", \"NODEVssh\", \"d211-116-254-214.rev.krline.net\")'}],\n",
    "}\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": instruction}]\n",
    "messages.append(demonstrations[dataset][0])\n",
    "messages.append(demonstrations[dataset][1])\n",
    "log = 'Jun 15 02:04:59 combo sshd(pam_unix)[20898]: authentication failure; logname= uid=0 euid=0 tty=NODEVssh ruser= rhost=220-135-151-1.hinet-ip.hinet.net  user=root'\n",
    "messages.append({\"role\": \"user\", \"content\": log})\n",
    "response = get_responce(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000, Recall: 0.9994, F1_measure: 0.9997, Group Accuracy: 0.9260, Message-Level Accuracy: 0.9925, Edit Distance: 0.1455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.926, 0.9925, 0.1455, 2.2247089135435227)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluator import evaluate\n",
    "import pandas as pd\n",
    "dataset = 'Spark'\n",
    "file = f'outputs/enhanced_gpt/1shot/{dataset}.csv'\n",
    "\n",
    "\n",
    "def extract_and_replace(input_string):\n",
    "    # 提取第一个“”中的内容\n",
    "    start = input_string.find('\"') + 1\n",
    "    end = input_string.find('\"', start)\n",
    "    extracted = input_string[start:end]\n",
    "    # 将所有{}替换成<*>\n",
    "    replaced = extracted.replace('{}', '<*>')\n",
    "    return replaced\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df['LogTemplate'] = df['LoggingStatement'].apply(extract_and_replace)\n",
    "df.to_csv(file, index=False)\n",
    "evaluate(file,dataset, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
