{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. {total} = 1072, {boot} = 856, {init} = 210, {finish} = 6\n",
      "2. {total} = 1114, {boot} = 885, {init} = 223, {finish} = 6\n",
      "3. {total} = 1074, {boot} = 869, {init} = 199, {finish} = 6\n",
      "4. {total} = 1078, {boot} = 851, {init} = 219, {finish} = 8\n",
      "5. {total} = 1077, {boot} = 865, {init} = 206, {finish} = 6\n",
      "6. {total} = 38, {boot} = 11, {init} = 27, {finish} = 0\n",
      "7. {total} = 42, {boot} = 12, {init} = 30, {finish} = 0\n",
      "8. {total} = 41, {boot} = 15, {init} = 26, {finish} = 0\n",
      "9. {total} = 40, {boot} = 7, {init} = 33, {finish} = 0\n",
      "10. {total} = 42, {boot} = 13, {init} = 28, {finish} = 1\n",
      "11. {total} = 42, {boot} = -4131, {init} = 4172, {finish} = 1\n",
      "12. {total} = 41, {boot} = -4122, {init} = 4162, {finish} = 1\n",
      "13. {total} = 42, {boot} = -4121, {init} = 4162, {finish} = 1\n",
      "14. {total} = 42, {boot} = -4138, {init} = 4179, {finish} = 1\n",
      "15. {total} = 42, {boot} = -4134, {init} = 4175, {finish} = 1\n",
      "16. {total} = 39, {boot} = -147, {init} = 186, {finish} = 0\n",
      "17. {total} = 39, {boot} = -147, {init} = 186, {finish} = 0\n",
      "18. {total} = 41, {boot} = -139, {init} = 179, {finish} = 1\n",
      "19. {total} = 38, {boot} = -156, {init} = 194, {finish} = 0\n",
      "20. {total} = 39, {boot} = -159, {init} = 198, {finish} = 0\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import openai\n",
    "import backoff\n",
    "\n",
    "api_key = \"sk-ShmyeH9VjAnRuT1S55A71a9fC69640948d20F73bA634C3A5\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://oneapi.xty.app/v1\",  # 中转url\n",
    "    api_key=api_key,                      # api_key\n",
    "    http_client=httpx.Client(\n",
    "        proxies=\"http://127.0.0.1:7890\"  # 代理地址\n",
    "    ),\n",
    ")\n",
    "\n",
    "@backoff.on_exception(backoff.expo, (openai.APIStatusError, openai.InternalServerError), max_tries=5)\n",
    "def get_responce(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip('\\n')\n",
    "\n",
    "\n",
    "instruction1 = \"given some log contents, the assistant should check if the following log contents share the same template.If so, abstract variables with ‘{placeholders}’ and return the template, otherwise return the templates and a list that represents the template used by each log\"\n",
    "\n",
    "instruction2 = \"there is an exsiting log template: '{domain}:{port} error : A connection request was canceled before the completion.', the assistant should check if the following log contents share the same template I provided or you sh.If so, abstract variables with ‘{placeholders}’ and return the template, otherwise return the templates and a list that represents the template used by each log\"\n",
    "\n",
    "instruction0 = '''The AI assistant can parse some log contents to one or more templates: {\"templates\": [], \"index\": []}.The \"templates\" (list) field denotes the templates that the log contents use. The \"index\" (list) field denotes the index of template each log content use. You should abstract variables with ‘{placeholders}’ and only return the dictionary'''\n",
    "\n",
    "instruction2 = '''Giving some log tempaltes, the AI assistant should merge the possibly same templates'''\n",
    "\n",
    "instruction_noindex = '''by abstracting variables with {}, The AI assistant can parse some the giving log contents to most possibly one or two template. Only return the template or tempaltes without additonal explanation'''\n",
    "\n",
    "prompt = '''Times: total = 1072, boot = 856, init = 210, finish = 6\n",
    "Times: total = 1114, boot = 885, init = 223, finish = 6\n",
    "Times: total = 1074, boot = 869, init = 199, finish = 6\n",
    "Times: total = 1078, boot = 851, init = 219, finish = 8\n",
    "Times: total = 1077, boot = 865, init = 206, finish = 6\n",
    "Times: total = 38, boot = 11, init = 27, finish = 0\n",
    "Times: total = 42, boot = 12, init = 30, finish = 0\n",
    "Times: total = 41, boot = 15, init = 26, finish = 0\n",
    "Times: total = 40, boot = 7, init = 33, finish = 0\n",
    "Times: total = 42, boot = 13, init = 28, finish = 1\n",
    "Times: total = 42, boot = -4131, init = 4172, finish = 1\n",
    "Times: total = 41, boot = -4122, init = 4162, finish = 1\n",
    "Times: total = 42, boot = -4121, init = 4162, finish = 1\n",
    "Times: total = 42, boot = -4138, init = 4179, finish = 1\n",
    "Times: total = 42, boot = -4134, init = 4175, finish = 1\n",
    "Times: total = 39, boot = -147, init = 186, finish = 0\n",
    "Times: total = 39, boot = -147, init = 186, finish = 0\n",
    "Times: total = 41, boot = -139, init = 179, finish = 1\n",
    "Times: total = 38, boot = -156, init = 194, finish = 0\n",
    "Times: total = 39, boot = -159, init = 198, finish = 0\n",
    "'''\n",
    "\n",
    "prompt2 = '''Finished task {task} in stage {stage} (TID {ID}). {bytes} bytes result sent to driver\n",
    "Finished task {task} in stage {stage} (TID {ID}). 2087 bytes result sent to driver\n",
    "Finished task 3.0 in stage {stage} (TID {ID}). {bytes} bytes result sent to driver\n",
    "Running task {task} in stage {stage} (TID {ID})'''\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": instruction_noindex}]\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "print(get_responce(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9738, Recall: 0.5896, F1_measure: 0.7345, Group Accuracy: 0.2385, Message-Level Accuracy: 0.6090, Edit Distance: 1.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2385, 0.609, 1.48, 2.9768439663509403)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluator import evaluate\n",
    "import pandas as pd\n",
    "dataset = 'Linux'\n",
    "file = f'outputs/enhanced_gpt/1shot/{dataset}.csv'\n",
    "evaluate(file, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证按' '分词有多少词，以及含数字的词占多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 / 9841\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "datasets = ['BGL' ,'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac','Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "a = 0\n",
    "b = 0\n",
    "list = []\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f\"dataset\\{dataset}\\{dataset}_2k.log_templates_corrected.csv\")\n",
    "    list = df['EventTemplate'].tolist()    \n",
    "    total_words = 0\n",
    "    words_with_numbers = 0\n",
    "\n",
    "    for s in list:\n",
    "        words = s.split()\n",
    "        total_words += len(words)\n",
    "        words_with_numbers += len([word for word in words if re.search(r'\\d', word)])\n",
    "    a+=total_words\n",
    "    b+=words_with_numbers\n",
    "\n",
    "print(f\"{b} / {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Log: Block broadcast_0 stored as values in memory (estimated size 384.0 B, free 317.5 KB)'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# load demonstrations\n",
    "with open('demonstrations.json', 'r') as f:\n",
    "    demonstrations = json.load(f)\n",
    "messages = []\n",
    "print(demonstrations['Spark'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
