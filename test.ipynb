{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51978/51978 [00:00<00:00, 2885086.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607680172380623\n",
      "44741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.evaluator import evaluate\n",
    "dataset = 'Apache'\n",
    "output_file = f'outputs/parser/LogBatcher_0shot_32candidate_10batchsize_2000chunksize_full/{dataset}_2k.log_structured.csv'\n",
    "groundtruth_file = f'dataset/{dataset}/{dataset}_full.log_structured.csv'\n",
    "# a =evaluate(output_file=output_file, groundtruth_file=groundtruth_file,dataset=dataset)\n",
    "# print(a)\n",
    "df1 = pd.read_csv(output_file)\n",
    "logs1 = df1['EventTemplate'].tolist()\n",
    "df2 = pd.read_csv(groundtruth_file)\n",
    "logs2 = df2['EventTemplate'].tolist()\n",
    "\n",
    "count = 0\n",
    "length = len(logs1)\n",
    "for i in tqdm(range(length)):\n",
    "    if logs1[i] == logs2[i]:\n",
    "        count += 1\n",
    "print(count / length)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.postprocess import correct_single_template\n",
    "\n",
    "print(correct_single_template('<*> \"<*> <*> 1.2.3.4:<*> status: <*> len: <*> time: <*>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "dataset = 'HDFS'\n",
    "groundtruth_file = f'dataset/{dataset}/{dataset}_full.log_structured.csv'\n",
    "df = pd.read_csv(groundtruth_file)\n",
    "# 定义更新规则的函数\n",
    "def update_content(content):\n",
    "    # 使用正则表达式匹配并更新内容\n",
    "    pattern = r'(BLOCK\\* NameSystem\\.allocateBlock: [^ ]*) ([^ ]*)'\n",
    "    replacement = r'\\1. \\2'\n",
    "    return re.sub(pattern, replacement, content)\n",
    "\n",
    "# 更新Content列\n",
    "df['Content'] = df['Content'].apply(update_content)\n",
    "\n",
    "# 保存修改后的CSV文件\n",
    "df.to_csv('updated_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLA:  0.9746803300440204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4631261it [20:44, 3722.82it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED:  0.3391685331489631\n",
      "NED:  0.9961445201966975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [01:35<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA:  0.9103974058037325\n",
      "         BGL: group Accuracy: 0.9104, Message-Level Accuracy: 0.9747, Edit Distance: 0.3392, Normalized Edit Distance: 0.996145\n",
      "(0.9103974058037325, 0.9746803300440204, 0.3391685331489631, 0.9961445201966975)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.evaluator import evaluate\n",
    "dataset = 'BGL'\n",
    "output_file = f'outputs/parser/LILAC_full/{dataset}_full.log_structured.csv'\n",
    "# output_file ='outputs/parser/LogBatcher_0shot_32candidate_10batchsize/BGL_2k.log_structured.csv'\n",
    "groundtruth_file = f'dataset/{dataset}/{dataset}_full.log_structured.csv'\n",
    "# groundtruth_file = 'dataset/BGL/BGL_2k.log_structured_corrected.csv'\n",
    "a =evaluate(output_file=output_file, groundtruth_file=groundtruth_file,dataset=dataset)\n",
    "print(a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogBatcher_0shot_32candidate_10batchsize_2000chunksize_full_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "86968 260.3832335329341\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import tiktoken\n",
    "def count_message_tokens(messages, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 初始化token计数\n",
    "    token_count = 0\n",
    "\n",
    "    # 计算每个消息的token数\n",
    "    for message in messages:\n",
    "        role_tokens = encoder.encode(message['role'])\n",
    "        content_tokens = encoder.encode(message['content'])\n",
    "        token_count += len(role_tokens) + \\\n",
    "            len(content_tokens) + 4  # 加上特殊的消息分隔符的token数\n",
    "\n",
    "    return token_count\n",
    "\n",
    "dataset = 'BGL'\n",
    "\n",
    "counts_token = 0\n",
    "counts_message = 0\n",
    "\n",
    "# 存储解析后的日志列表\n",
    "message_list = []\n",
    "# load every message\n",
    "with open('outputs/cost/cost_full_LILAC_32_3_BGL.json', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == '[':\n",
    "            list_str = ''\n",
    "            start_load = True\n",
    "        if line.strip() == ']':\n",
    "            list_str += line\n",
    "            message = json.loads(list_str)\n",
    "            message_list.append(message)\n",
    "            start_load = False\n",
    "        if start_load:\n",
    "            list_str += line\n",
    "print(len(message_list))\n",
    "\n",
    "# remove the same log messages\n",
    "# def make_hashable(log_list):\n",
    "#     return tuple(tuple(sorted(d.items())) for d in log_list)\n",
    "# message_list = list(set(make_hashable(log_list) for log_list in message_list))\n",
    "# message_list = [list(map(dict, log_list)) for log_list in message_list]\n",
    "# print(len(message_list))\n",
    "\n",
    "for message in message_list:\n",
    "    counts_token += count_message_tokens(message, 'gpt-3.5-turbo')\n",
    "    counts_message += 1\n",
    "print(counts_token, counts_token/counts_message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
