{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invokation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import httpx\n",
    "import openai\n",
    "import backoff\n",
    "from utils.postprocess import post_process\n",
    "\n",
    "api_key = \"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\"\n",
    "client = OpenAI(\n",
    "    api_key=api_key,                      # api_key\n",
    "    http_client=httpx.Client(\n",
    "        proxies=\"http://127.0.0.1:7890\"  # proxies\n",
    "    ),\n",
    ")\n",
    "\n",
    "@backoff.on_exception(backoff.expo, (openai.APIStatusError, openai.InternalServerError), max_tries=20)\n",
    "def get_responce(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    print(f\"model: {response.model}\")\n",
    "    print(f\"usage: {response.usage}\")\n",
    "    return response.choices[0].message.content.strip('\\n')\n",
    "\n",
    "instruction_for_batch_logs = '''You will be provided with some log messages. You should check if the giving log messages share the same template. If so, abstract variables with `{{placeholders}}` to extract the corresponding template.\\nPrint the input log's template delimited by backticks.'''\n",
    "\n",
    "instruction_for_one_log = \"You will be provided with some log messages delimited by backticks. You must abstract variables with `{{placeholders}}` to extract the corresponding template. There is a high possiblity that no variables in the log message\\nPrint the input log's template delimited by backticks.\"\n",
    "\n",
    "instruction_for_all = \"You will be provided with some log messages separated by line break. You must abstract variables with `{{placeholders}}` to extract the corresponding template. There might be no variables in the log message\\nPrint the input log's template delimited by backticks.\"\n",
    "\n",
    "logs = '''data storage interrupt'''\n",
    "log_list = logs.split('\\n')\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': instruction_for_all},\n",
    "    {'role': 'user', 'content': logs}\n",
    "]\n",
    "\n",
    "output = get_responce(messages)\n",
    "template = post_process(output, log_list[0])\n",
    "print(output.strip('\\n'))\n",
    "print(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def count_message_tokens(messages, model_name):\n",
    "    # 根据模型名称加载合适的编码器\n",
    "    if model_name == \"gpt-4\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    elif model_name == \"gpt-3.5-turbo\":\n",
    "        encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    else:\n",
    "        raise ValueError(\"未知的模型名称\")\n",
    "\n",
    "    # 初始化token计数\n",
    "    token_count = 0\n",
    "\n",
    "    # 计算每个消息的token数\n",
    "    for message in messages:\n",
    "        role_tokens = encoder.encode(message['role'])\n",
    "        content_tokens = encoder.encode(message['content'])\n",
    "        token_count += len(role_tokens) + len(content_tokens) + 4  # 加上特殊的消息分隔符的token数\n",
    "\n",
    "    return token_count\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': \"You will be provided with some log messages separated by line break. You must abstract variables with `{{placeholders}}` to extract the corresponding template. There might be no variables in the log message\\nPrint the input log's template delimited by backticks.\"},\n",
    "    {'role': 'user', 'content': 'data storage interrupt'}\n",
    "]\n",
    "\n",
    "# token num\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "token_count = count_message_tokens(messages, model_name)\n",
    "print(f\"in {model_name} the num of token is: {token_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "\n",
    "\n",
    "def closest_template(target, templates):\n",
    "    min_distance = float('inf')\n",
    "    closest_template = None\n",
    "    for template in templates:\n",
    "        d = distance(target, template.replace('<*>', ''))\n",
    "        print(d)\n",
    "        if d < min_distance:\n",
    "            min_distance = d\n",
    "            closest_template = template\n",
    "    return closest_template\n",
    "\n",
    "templates = [\n",
    "    '<*> close, <*> bytes sent, <*> bytes received, lifetime <1',\n",
    "    '<*> close, <*> bytes (<*> KB) sent, <*> bytes (<*> KB) received, lifetime <1',\n",
    "    '<*> close, <*> bytes sent, <*> bytes (<*> KB) received, lifetime <*>',\n",
    "    '<*> close, <*> bytes (<*> KB) sent, <*> bytes (<*> MB) received, lifetime <*>',\n",
    "    '<*> close, <*> sent, <*> received, lifetime <*>',\n",
    "]\n",
    "\n",
    "print(closest_template('proxy.cse.cuhk.edu.hk:5070 close, 0 bytes sent, 0 bytes received, lifetime 00:01', templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_most_similar(target, lst, n=3):\n",
    "    vectors = [np.array([ord(c) for c in s]).reshape(1, -1) for s in lst]\n",
    "    target_vector = np.array([ord(c) for c in target]).reshape(1, -1)\n",
    "    similarities = cosine_similarity(vectors, target_vector)\n",
    "    most_similar_indices = np.argsort(similarities, axis=0)[-n:].flatten()[::-1]\n",
    "    return [lst[i] for i in most_similar_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test oracle template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.postprocess import correct_single_template\n",
    "import pandas as pd\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Linux HealthApp Apache Proxifier OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "# define a set\n",
    "list = []\n",
    "for dataset in datasets:\n",
    "    print('+' * 20 + dataset)\n",
    "    df = pd.read_csv(\n",
    "        f'dataset\\{dataset}\\{dataset}_2k.log_templates_corrected.csv')\n",
    "    templates = df['EventTemplate'].tolist()\n",
    "    for template in templates:\n",
    "        if correct_single_template(template) != template:\n",
    "            print(correct_single_template(template))\n",
    "            print(template)\n",
    "            print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to conclude the types of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from utils.sample_byword import extract_variables\n",
    "\n",
    "# extract before check\n",
    "def check_variable(variable):\n",
    "    variable = variable.strip()\n",
    "    if variable.startswith('/'):\n",
    "        return 'path'\n",
    "    if variable.startswith('0x'):\n",
    "        return 'address'\n",
    "    if re.match(r'\\b-?\\d+(\\.\\d+)?\\b|\\b0x[0-9a-fA-F]+\\b', variable):\n",
    "        return 'number'\n",
    "    if re.match( r'^[a-zA-Z]+$', variable):\n",
    "        return 'word'\n",
    "    if re.match(  r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}(?::\\d{1,5})?\\b', variable):\n",
    "        return 'ip'\n",
    "    else:\n",
    "        return 'null'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the unseen accurray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "table_order = 'HDFS Hadoop Spark Zookeeper BGL HPC Thunderbird Windows Linux Android HealthApp Apache OpenSSH OpenStack Mac'\n",
    "datasets = table_order.split(' ')\n",
    "a = 0\n",
    "b = 0\n",
    "for dataset in datasets:\n",
    "    \n",
    "    file = 'Test_10shot'\n",
    "    groundtruth_file = f'dataset/{dataset}/{dataset}_2k.log_structured_corrected.csv'\n",
    "    output_file = f'outputs/parser/{file}/{dataset}_2k.log_structured.csv'\n",
    "    \n",
    "    templates_groundtruth = pd.read_csv(groundtruth_file)['EventTemplate'].tolist()\n",
    "    templates_output = pd.read_csv(output_file)['EventTemplate'].tolist()\n",
    "    \n",
    "    freq = Counter(templates_groundtruth)\n",
    "    unseen_templates = [item for item, count in freq.items() if count == 1]\n",
    "    \n",
    "    indexes = []\n",
    "    for index, template in enumerate(templates_groundtruth):\n",
    "        if template in unseen_templates:\n",
    "            indexes.append(index)\n",
    "    \n",
    "    accuracy_exact_string_matching = accuracy_score([templates_groundtruth[index] for index in indexes], [templates_output[index] for index in indexes], normalize=False)\n",
    "    length = len(indexes)\n",
    "    a += length\n",
    "    b += accuracy_exact_string_matching\n",
    "    dataset = ' ' * (12 - len(dataset)) + dataset\n",
    "    print('%s: len of unseen log: %.4d, Message-Level Accuracy: %.4f' %(dataset, length ,accuracy_exact_string_matching/length))\n",
    "    \n",
    "\n",
    "print(b/a)\n",
    "print(a/len(datasets))\n",
    "# 81.0 71.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
