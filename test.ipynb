{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the log templates provided, the most correct one is:\n",
      "\n",
      "<*>:<*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import openai\n",
    "import backoff\n",
    "\n",
    "api_key = \"sk-ShmyeH9VjAnRuT1S55A71a9fC69640948d20F73bA634C3A5\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://oneapi.xty.app/v1\",  # 中转url\n",
    "    api_key=api_key,                      # api_key\n",
    "    http_client=httpx.Client(\n",
    "        proxies=\"http://127.0.0.1:7890\"  # 代理地址\n",
    "    ),\n",
    ")\n",
    "\n",
    "@backoff.on_exception(backoff.expo, (openai.APIStatusError, openai.InternalServerError), max_tries=5)\n",
    "def get_responce(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip('\\n')\n",
    "\n",
    "\n",
    "instruction_hoang = '''You will be provided with some log messages delimited by backticks. You should check if the given log messages share the same template.If so, abstract variables with ‘{placeholders}’ and return the template without additional explatation, otherwise return the template list'''\n",
    "\n",
    "\n",
    "instruction0 = '''Gving some log raws, the AI assistant can parse them to one or more templates: {\"template\": ['template_1']}.The \"templates\" field (list) denotes the templates that the log contents use. You should abstract variables with ‘{placeholders}’ and only return the dictionary'''\n",
    "\n",
    "instruction2 = '''Giving some log tempaltes from some log contents which may use the same template, the AI assistant should merge the similar templates into a single template'''\n",
    "\n",
    "instruction_noindex = '''You will be provided with some log messages. You should check if the giving log messages share the same template. If so, abstract variables with ‘{placeholders}’ and return the template without additional explatation, otherwise return the templates'''\n",
    "\n",
    "instruction_100 = '''do the following log contents share the same template? Return the template or templates without additional explatation'''\n",
    "\n",
    "instruction_1_13 = '''You will be provided with some log messages. You should check whether the giving log messages share the same template. If so, abstract variables with ‘{placeholders}’ and return the template without additional explatation'''\n",
    "\n",
    "instruction_1_13_2 = '''Given some log templates, you should choice the most corret one. If you think none of them is correct, you can return the correct tempalte you think'''\n",
    "\n",
    "prompt = '''Block broadcast_9 stored as values in memory (estimated size 8.8 KB, free 14.0 KB)\n",
    "Block broadcast_8 stored as values in memory (estimated size 281.6 KB, free 317.0 KB)\n",
    "Block broadcast_10 stored as values in memory (estimated size 9.6 KB, free 339.2 KB)\n",
    "Block broadcast_11 stored as values in memory (estimated size 9.2 KB, free 353.9 KB)\n",
    "Block broadcast_12 stored as values in memory (estimated size 9.8 KB, free 369.3 KB)\n",
    "Block broadcast_13 stored as values in memory (estimated size 10.1 KB, free 386.5 KB)\n",
    "Block broadcast_14 stored as values in memory (estimated size 9.6 KB, free 401.9 KB)\n",
    "Block broadcast_15 stored as values in memory (estimated size 9.2 KB, free 416.6 KB)\n",
    "Block broadcast_16 stored as values in memory (estimated size 9.8 KB, free 432.0 KB)\n",
    "Block broadcast_17 stored as values in memory (estimated size 10.1 KB, free 448.6 KB)\n",
    "Block broadcast_18 stored as values in memory (estimated size 9.6 KB, free 464.0 KB)\n",
    "Block broadcast_19 stored as values in memory (estimated size 9.2 KB, free 478.6 KB)\n",
    "Block broadcast_20 stored as values in memory (estimated size 9.8 KB, free 411.6 KB)\n",
    "Block broadcast_21 stored as values in memory (estimated size 10.1 KB, free 403.2 KB)\n",
    "Block broadcast_22 stored as values in memory (estimated size 9.6 KB, free 418.6 KB)\n",
    "Block broadcast_23 stored as values in memory (estimated size 9.2 KB, free 387.4 KB)\n",
    "Block broadcast_24 stored as values in memory (estimated size 9.8 KB, free 402.8 KB)'''\n",
    "\n",
    "prompt2 = '''<*>:<*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
    "<*>: <*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
    "<*>:<*> open through proxy <*>:<*> HTTPS\n",
    "<*>:<*> open through proxy proxy.cse.cuhk.edu.hk:5070 <*>\n",
    "<*>:<*> open through proxy proxy.<*>:<*> HTTPS\n",
    "<*>:443 open through proxy <*>:5070 HTTPS\n",
    "<*>:<*> open through proxy <*>:<*> <*>\n",
    "<*>:open through proxy <*>:HTTPS'''\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": instruction_1_13_2}]\n",
    "messages.append({\"role\": \"user\", \"content\": prompt2})\n",
    "print(get_responce(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9738, Recall: 0.5896, F1_measure: 0.7345, Group Accuracy: 0.2385, Message-Level Accuracy: 0.6090, Edit Distance: 1.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2385, 0.609, 1.48, 2.9768439663509403)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluator import evaluate\n",
    "import pandas as pd\n",
    "dataset = 'Linux'\n",
    "file = f'outputs/enhanced_gpt/1shot/{dataset}.csv'\n",
    "evaluate(file, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证按' '分词有多少词，以及含数字的词占多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 / 9841\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "datasets = ['BGL' ,'HDFS', 'Linux', 'HealthApp', 'OpenStack', 'OpenSSH', 'Proxifier', 'HPC', 'Zookeeper', 'Mac','Hadoop', 'Android', 'Windows', 'Apache', 'Thunderbird', 'Spark']\n",
    "a = 0\n",
    "b = 0\n",
    "list = []\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(f\"dataset\\{dataset}\\{dataset}_2k.log_templates_corrected.csv\")\n",
    "    list = df['EventTemplate'].tolist()    \n",
    "    total_words = 0\n",
    "    words_with_numbers = 0\n",
    "\n",
    "    for s in list:\n",
    "        words = s.split()\n",
    "        total_words += len(words)\n",
    "        words_with_numbers += len([word for word in words if re.search(r'\\d', word)])\n",
    "    a+=total_words\n",
    "    b+=words_with_numbers\n",
    "\n",
    "print(f\"{b} / {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'Log: Block broadcast_0 stored as values in memory (estimated size 384.0 B, free 317.5 KB)'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# load demonstrations\n",
    "with open('demonstrations.json', 'r') as f:\n",
    "    demonstrations = json.load(f)\n",
    "messages = []\n",
    "print(demonstrations['Spark'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类结果的自定义处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
      "<*>: <*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
      "<*> open through proxy <*> HTTPS\n",
      "<*> open through proxy proxy.cse.cuhk.edu.hk:5070 <*>\n",
      "<*> open through proxy <*> HTTPS\n",
      "<*>:443 open through proxy <*>:5070 HTTPS\n",
      "<*> open through proxy <*> <*>\n",
      "<*>:open through proxy <*>:HTTPS\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_words(s):\n",
    "    words = s.split(' ')\n",
    "    for i in range(len(words)):\n",
    "        if words[i].count('<*>') >= 2:\n",
    "            if words[i].endswith(':'):\n",
    "                words[i] = '<*>:'\n",
    "            elif words[i].endswith(','):\n",
    "                words[i] = '<*>,'\n",
    "            elif words[i].endswith('.'):\n",
    "                words[i] = '<*>.'\n",
    "            else:\n",
    "                words[i] = '<*>'\n",
    "    # zookeeper\n",
    "    # output_str = input_str.replace(' /<*>', ' <*>')\n",
    "    return ' '.join(words)\n",
    "\n",
    "# 测试\n",
    "\n",
    "\n",
    "inputs = '''<*>:<*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
    "<*>: <*> open through proxy proxy.cse.cuhk.edu.hk:5070 HTTPS\n",
    "<*>:<*> open through proxy <*>:<*> HTTPS\n",
    "<*>:<*> open through proxy proxy.cse.cuhk.edu.hk:5070 <*>\n",
    "<*>:<*> open through proxy proxy.<*>:<*> HTTPS\n",
    "<*>:443 open through proxy <*>:5070 HTTPS\n",
    "<*>:<*> open through proxy <*>:<*> <*>\n",
    "<*>:open through proxy <*>:HTTPS'''\n",
    "\n",
    "lines = inputs.split('\\n')\n",
    "for line in lines:\n",
    "    print(replace_words(line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
